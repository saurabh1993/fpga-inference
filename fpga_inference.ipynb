{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/centos/ml-suite/notebooks\n",
      "Running on host: ip-172-31-82-102.ec2.internal\n",
      "Running w/ LD_LIBRARY_PATH: /opt/xilinx/xrt/lib::/home/centos/ml-suite/ext/boost/lib:/home/centos/ml-suite/ext/zmq/libs:/home/centos/ml-suite/overlaybins/aws/runtime/lib/x86_64\n",
      "Running w/ XILINX_OPENCL: /home/centos/ml-suite/overlaybins/aws\n",
      "Running w/ XCLBIN_PATH: /home/centos/ml-suite/overlaybins/aws\n",
      "Running w/ PYTHONPATH: /home/centos/ml-suite:/home/centos/ml-suite/xfdnn/rt:/home/centos/ml-suite/ext:/home/centos/ml-suite/models/darknet/tools:/home/centos/ml-suite/apps/yolo:/home/centos/ml-suite/apps/yolo/nms:/home/centos/ml-suite/xfdnn/tools/emu:/home/centos/ml-suite/xfdnn/tools/compile/network:/home/centos/ml-suite/xfdnn/tools/compile/graph:/home/centos/ml-suite/xfdnn/tools/compile/optimizations:/home/centos/ml-suite/xfdnn/tools/compile/codegeneration:/home/centos/ml-suite/xfdnn/tools/compile/memory:/home/centos/ml-suite/xfdnn/tools/compile/version:/home/centos/ml-suite/xfdnn/tools/compile/memory:/home/centos/ml-suite/xfdnn/tools/compile/weights:/home/centos/ml-suite/xfdnn/tools/compile/bin:/home/centos/ml-suite/xfdnn/tools/compile/parallel:/home/centos/ml-suite/xfmlp/python\n",
      "Running w/ SDACCEL_INI_PATH: /home/centos/ml-suite/overlaybins\n"
     ]
    }
   ],
   "source": [
    "# Import some things\n",
    "import os,sys,cv2\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Bring in Xilinx ML Suite Compiler, Quantizer, PyXDNN\n",
    "from xfdnn.tools.compile.bin.xfdnn_compiler_tensorflow import TFFrontend as xfdnnCompiler\n",
    "from xfdnn.tools.quantize.quantize_tf import tf_Quantizer as xfdnnQuantizer\n",
    "import xfdnn.rt.xdnn as xdnn\n",
    "import xfdnn.rt.xdnn_io as xdnn_io\n",
    "import time\n",
    "import ipywidgets\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "import pandas as pd\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "print(\"Current working directory: %s\" % os.getcwd())\n",
    "print(\"Running on host: %s\" % os.uname()[1])\n",
    "print(\"Running w/ LD_LIBRARY_PATH: %s\" %  os.environ[\"LD_LIBRARY_PATH\"])\n",
    "print(\"Running w/ XILINX_OPENCL: %s\" %  os.environ[\"XILINX_OPENCL\"])\n",
    "print(\"Running w/ XCLBIN_PATH: %s\" %  os.environ[\"XCLBIN_PATH\"])\n",
    "print(\"Running w/ PYTHONPATH: %s\" %  os.environ[\"PYTHONPATH\"])\n",
    "print(\"Running w/ SDACCEL_INI_PATH: %s\" %  os.environ[\"SDACCEL_INI_PATH\"])\n",
    "\n",
    "id = !whoami\n",
    "\n",
    "# Make sure there is no error in this cell\n",
    "# The xfDNN runtime depends upon the above environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeFpgaModel(sProtoBufPath):\n",
    "    config = {} # Config dict\n",
    "    config[\"platform\"] = 'aws'\n",
    "    \n",
    "    sInputNode,sOutputNode = getModelInputOutputNode(sProtoBufPath)\n",
    "    # Compiler Arguments\n",
    "    config[\"model\"] = \"GoogLeNet\"\n",
    "    #config[\"protobuf\"] = \"/home/centos/models/tensorflow/inception/frozen_inception_v3.pb\"\n",
    "    config[\"protobuf\"] = sProtoBufPath\n",
    "    #config[\"outmodel\"] = \"work/optimized_model\" # String for naming optimized model NOT YET SUPPORTED\n",
    "    config[\"netcfg\"] = \"work/fpga.cmds\" # Compiler will generate FPGA instructions\n",
    "    config[\"memory\"] = 5 # Available on-chip SRAM\n",
    "    config[\"dsp\"] = 56 # Width of Systolic Array\n",
    "    config[\"finalnode\"] = sOutputNode # Terminal node in your tensorflow graph\n",
    "    #config[\"finalnode\"] = \"prob\" # Terminal node in your tensorflow graph\n",
    "\n",
    "    compiler = xfdnnCompiler(\n",
    "        networkfile=config[\"protobuf\"],      # Protobuf filename: input file\n",
    "        #anew=config[\"outmodel\"],            # String for intermediate protobuf NOT YET SUPPORTED\n",
    "        generatefile=config[\"netcfg\"],       # Script filename: output file\n",
    "        memory=config[\"memory\"],             # Available on chip SRAM within xclbin\n",
    "        dsp=config[\"dsp\"],                   # Rows in DSP systolic array within xclbin # keep defaults \n",
    "        finalnode=config[\"finalnode\"],       # Terminal node in your tensorflow graph\n",
    "        weights=True                         # Instruct Compiler to generate a weights directory for runtime\n",
    "    )\n",
    "\n",
    "    # Invoke compiler\n",
    "    try:\n",
    "        compiler.compile()\n",
    "\n",
    "        # The compiler extracts the floating point weights from the .caffemodel. \n",
    "        # This weights dir will be stored in the work dir with the appendex '_data'. \n",
    "        # The compiler will name it after the caffemodel, and append _data\n",
    "        config[\"datadir\"] = \"work/\" + os.path.basename(config[\"protobuf\"]) + \"_data\"\n",
    "\n",
    "        if os.path.exists(config[\"datadir\"]) and os.path.exists(config[\"netcfg\"]+\".json\"):\n",
    "            print(\"Compiler successfully generated JSON and the data directory: {:s}\".format(config[\"datadir\"]))\n",
    "        else:\n",
    "            print(\"Compiler failed to generate the JSON or data directory: {:s}\".format(config[\"datadir\"]))\n",
    "            raise\n",
    "\n",
    "        print(\"**********\\nCompilation Successful!\\n\")\n",
    "\n",
    "        import json\n",
    "        data = json.loads(open(config[\"netcfg\"]+\".json\").read())\n",
    "        print(\"Network Operations Count: {:d}\".format(data['ops']))\n",
    "        print(\"DDR Transfers (bytes): {:d}\".format(data['moveops']))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Failed to complete compilation:\",e)\n",
    "\n",
    "    # Quantizing\n",
    "    config[\"img_mean\"] = [104.007, 116.669, 122.679] # Mean of the training set\n",
    "    config[\"quantizecfg\"] = \"work/quantization_params.json\" # Quantizer will generate quantization params\n",
    "    config[\"calibration_directory\"] = \"../xfdnn/tools/quantize/calibration_directory\" # Directory of images for quantizer\n",
    "    config[\"calibration_size\"] = 15 # Number of calibration images quantizer will use\n",
    "    config[\"bitwidths\"] = [16,16,16] # Supported quantization precision\n",
    "    config[\"img_raw_scale\"] = 255.0 # Raw scale of input pixels, i.e. 0 <-> 255\n",
    "    config[\"img_input_scale\"] = 1.0 # Input multiplier, Images are scaled by this factor after mean subtraction\n",
    "\n",
    "\n",
    "    quantizer = xfdnnQuantizer(\n",
    "        model_file=config[\"protobuf\"],          # Prototxt filename: input file\n",
    "        quantize_config=config[\"quantizecfg\"],  # Quant filename: output file\n",
    "        bitwidths=config[\"bitwidths\"],          # Fixed Point precision: 8b or 16b\n",
    "        cal_size=config[\"calibration_size\"],    # Number of calibration images to use\n",
    "        img_mean=config[\"img_mean\"],            # Image mean per channel to caffe transformer\n",
    "        cal_dir=config[\"calibration_directory\"] # Directory containing calbration images\n",
    "    )\n",
    "\n",
    "    # Invoke quantizer\n",
    "    try:\n",
    "        quantizer.quantize(inputName = sInputNode, outputName = sOutputNode)\n",
    "\n",
    "        import json\n",
    "        data = json.loads(open(config[\"quantizecfg\"]).read())\n",
    "        print(\"**********\\nSuccessfully produced quantization JSON file for %d layers.\\n\"%len(data['network']))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to quantize:\",e)\n",
    "\n",
    "    # Create a handle with which to communicate to the FPGA\n",
    "    # The actual handle is managed by xdnn\n",
    "    config[\"xclbin\"] = \"../overlaybins/\" + config[\"platform\"] + \"/overlay_3.xclbin\" # Chosen Hardware Overlay\n",
    "    ## NOTE: If you change the xclbin, we likely need to change some arguments provided to the compiler\n",
    "    ## Specifically, the DSP array width, and the memory arguments\n",
    "\n",
    "    ret, handles = xdnn.createHandle(config['xclbin'])\n",
    "\n",
    "    if ret:                                                             \n",
    "        print(\"ERROR: Unable to create handle to FPGA\")\n",
    "    else:\n",
    "        print(\"INFO: Successfully created handle to FPGA\")\n",
    "\n",
    "    # If this step fails, most likely the FPGA is locked by another user, or there is some setup problem with the hardware\n",
    "    return config,handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelInputOutputNode(sProtobufPath):\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.python.platform import gfile\n",
    "    with tf.Session() as sess:\n",
    "        with gfile.FastGFile(sProtobufPath,'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        sess.graph.as_default()\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "        graph_nodes=[n for n in graph_def.node]\n",
    "\n",
    "        return graph_nodes[0].name, graph_nodes[len(graph_nodes)-1].name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chose an image to run, display it for reference\n",
    "# config[\"images\"] = [\"../examples/classification/dog.jpg\",\"../examples/classification/dog.jpg\"] # Image of interest (Must provide as a list)\n",
    "\n",
    "# img = cv2.imread(config[\"images\"][0])\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(img)\n",
    "# plt.title(config[\"images\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize, and transfer the weights to FPGA DDR\n",
    "def TransferWeightsFPGA(iBatchSize,config,handles):\n",
    "    # config[\"datadir\"] = \"work/\" + config[\"caffemodel\"].split(\"/\")[-1]+\"_data\" # From Compiler\n",
    "    config[\"scaleA\"] = 10000 # Global scaler for weights (Must be defined)\n",
    "    config[\"scaleB\"] = 30 # Global scaler for bias (Must be defined)\n",
    "    config[\"PE\"] = 0 # Run on Processing Element 0 - Different xclbins have a different number of Elements\n",
    "    config[\"batch_sz\"] = iBatchSize # We will load 1 image at a time from disk\n",
    "    config[\"in_shape\"] = (3,224,224) # We will resize images to 224x224\n",
    "\n",
    "    #(weightsBlob, fcWeight, fcBias ) = pyxfdnn_io.loadWeights(config)\n",
    "    fpgaRT = xdnn.XDNNFPGAOp(handles,config)\n",
    "    (fcWeight, fcBias) = xdnn_io.loadFCWeightsBias(config)\n",
    "    return fpgaRT,fcWeight,fcBias,config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Allocate space in host memory for inputs, load images from disk, and prepare images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate space in host memory for inputs, Load images from disk\n",
    "def AllocateMemoryToHost(config):\n",
    "#     batch_array = np.empty(((config['batch_sz'],) + config['in_shape']), dtype=np.float32, order='C')\n",
    "#     img_paths = xdnn_io.getFilePaths(config['images'])\n",
    "\n",
    "#     for i in xrange(0, len(img_paths), config['batch_sz']):\n",
    "#         pl = []\n",
    "#         for j, p in enumerate(img_paths[i:i + config['batch_sz']]):\n",
    "#             batch_array[j, ...], _ = xdnn_io.loadImageBlobFromFile(p, config['img_raw_scale'], config['img_mean'], \n",
    "#                                                                       config['img_input_scale'], config['in_shape'][2], \n",
    "#                                                                       config['in_shape'][1])\n",
    "#             pl.append(p)\n",
    "    # Allocate space in host memory for outputs\n",
    "    if config[\"model\"] == \"GoogLeNet\":\n",
    "        config[\"fpgaoutsz\"] = 1024 # Number of elements in the activation of the last layer ran on the FPGA\n",
    "    elif config[\"model\"] == \"ResNet50\":\n",
    "        config[\"fpgaoutsz\"] = 2048 # Number of elements in the activation of the last layer ran on the FPGA\n",
    "\n",
    "    config[\"outsz\"] = 1000 # Number of elements output by FC layers (1000 used for imagenet)\n",
    "\n",
    "    fpgaOutput = np.empty ((config['batch_sz'], config['fpgaoutsz'],), dtype=np.float32, order='C') # Space for fpga output\n",
    "    fcOutput = np.empty((config['batch_sz'], config['outsz'],), dtype=np.float32, order='C') # Space for output of inner product\n",
    "   \n",
    "    return fpgaOutput, fcOutput,config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRandomBatch(iBatchSize,config):\n",
    "    return np.random.rand(iBatchSize,3,224,224).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12. Output the classification prediction scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the classification given the labels synset_words.txt (Imagenet classes)\n",
    "# config[\"labels\"] = \"../examples/classification/synset_words.txt\"\n",
    "# labels = xdnn_io.get_labels(config['labels'])\n",
    "# xdnn_io.printClassification(softmaxOut, pl, labels)\n",
    "\n",
    "# #Print Original Image for Reference \n",
    "# img = cv2.imread(config[\"images\"][0])\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(img)\n",
    "# plt.title(config[\"images\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runOnFPGA(iBatchSize,config,handle,batchArray):\n",
    "    # Load weights to FPGA\n",
    "    fpgaRT,fcWeight,fcBias,config=TransferWeightsFPGA(iBatchSize,config,handle)\n",
    "    \n",
    "    #Allocate Memory to host\n",
    "    fpgaOutput, fcOutput,config=AllocateMemoryToHost(config)\n",
    "    \n",
    "    #Generate Image batches to run\n",
    "#     batch_array= generateRandomBatch(iBatchSize,config)\n",
    "    \n",
    "    # Write FPGA Instructions to FPGA and Execute the network!\n",
    "    start = time.time()\n",
    "    fpgaRT.execute(batch_array, fpgaOutput)\n",
    "    \n",
    "    # Compute the inner product\n",
    "    xdnn.computeFC(fcWeight, fcBias, fpgaOutput, config['batch_sz'], config['outsz'], config['fpgaoutsz'], fcOutput)\n",
    "    \n",
    "    # Compute the softmax to convert the output to a vector of probabilities\n",
    "    softmaxOut = xdnn.computeSoftmax(fcOutput)\n",
    "    \n",
    "    #Return the output\n",
    "    return softmaxOut, time.time()-start    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(anew=None, approximate=False, banditpre=None, barrier=False, bridges=None, bytesperpixels=2, concatstrategy=None, conv_1x1_s2=False, cpulayermustgo=False, ddr=256, dedicateddsp=None, deephifilename=None, dsp=56, finalnode=u'prob', forceweights=None, fromtensorflow=False, generatefile='work/fpga.cmds', godreplication=None, lasttensorbyname=None, loadpickle=None, manasadebugmode=False, manualbatch=False, manualdeconv=False, memory=5, networkfile='/home/centos/models/tensorflow/bvlc_googlenet_without_lrn/fp32/bvlc_googlenet_without_lrn_test.pb', nodynamicscaling=False, noreplication=False, parallelism=False, parallelismstrategy=\"['bottom', 'tops']\", parallelread=None, pipelineconvmaxpool=False, placeholdershape=None, pngfile=None, poolingaround=False, rankdir='BT', savepickle=None, schedulefile=None, strategy='all', verbose=False, versionjson=None, weights=True)\n",
      "Network: /home/centos/models/tensorflow/bvlc_googlenet_without_lrn/fp32/bvlc_googlenet_without_lrn_test.pb\n",
      "GenerateCode: work/fpga.cmds\n",
      "Weights: True\n",
      "PngFile: None\n",
      "ConcatStrategy: None\n",
      "Strategy: all\n",
      "ScheduleFile: None\n",
      "DDR: 256\n",
      "DSP: 56\n",
      "DSP V2\n",
      "Verbose: False\n",
      "FromTF: False\n",
      "Memory: 5\n",
      "**************************************************\n",
      "* HARDWARE\n",
      "**************************************************\n",
      "Reading graph from /home/centos/models/tensorflow/bvlc_googlenet_without_lrn/fp32/bvlc_googlenet_without_lrn_test.pb\n",
      "placeholder None\n",
      "\n",
      "**************************************************\n",
      "* BUILDING DATA FLOW GRAPH\n",
      "**************************************************\n",
      "pre-build /home/centos/models/tensorflow/bvlc_googlenet_without_lrn/fp32/bvlc_googlenet_without_lrn_test.pb\n",
      "\n",
      "**************************************************\n",
      "* CONVERTING GRAPH TO SCHEDULE\n",
      "**************************************************\n",
      "1 10 Done Graphing\n",
      "1 10 Computation Islands 70\n",
      "1 Memory Islands 70\n",
      "2 10 Removed Identities 0\n",
      "3 10 Removed in place 0\n",
      "4 10 Removed Scale+ BIAS 0\n",
      "\t 5 10 Removed batch norm prev convolution 0\n",
      "5 10 Removed batch norm 57\n",
      "5 10 Removed batch norm 0\n",
      "6 10 Removed Bias into inner product: 1\n",
      "7 10 Removed ReLU 57\n",
      "8 10 Removed PAD 0\n",
      "9 10 Removed Reshape: 0\n",
      "\n",
      "###########################\n",
      " Schedule  84 84\n",
      "Time, layer name:\n",
      "0 [u'data']\n",
      "1 [u'conv1_7x7_s2/Conv2D']\n",
      "2 [u'pool1_3x3_s2']\n",
      "3 [u'conv2_3x3_reduce/Conv2D']\n",
      "4 [u'conv2_3x3/Conv2D']\n",
      "5 [u'pool2_3x3_s2']\n",
      "6 [u'inception_3a_pool']\n",
      "7 [u'inception_3a_1x1/Conv2D']\n",
      "8 [u'inception_3a_3x3_reduce/Conv2D']\n",
      "9 [u'inception_3a_3x3/Conv2D']\n",
      "10 [u'inception_3a_5x5_reduce/Conv2D']\n",
      "11 [u'inception_3a_5x5/Conv2D']\n",
      "12 [u'inception_3a_pool_proj/Conv2D']\n",
      "13 [u'inception_3a_output']\n",
      "14 [u'inception_3b_pool']\n",
      "15 [u'inception_3b_1x1/Conv2D']\n",
      "16 [u'inception_3b_3x3_reduce/Conv2D']\n",
      "17 [u'inception_3b_3x3/Conv2D']\n",
      "18 [u'inception_3b_5x5_reduce/Conv2D']\n",
      "19 [u'inception_3b_5x5/Conv2D']\n",
      "20 [u'inception_3b_pool_proj/Conv2D']\n",
      "21 [u'inception_3b_output']\n",
      "22 [u'pool3_3x3_s2']\n",
      "23 [u'inception_4a_pool']\n",
      "24 [u'inception_4a_1x1/Conv2D']\n",
      "25 [u'inception_4a_3x3_reduce/Conv2D']\n",
      "26 [u'inception_4a_3x3/Conv2D']\n",
      "27 [u'inception_4a_5x5_reduce/Conv2D']\n",
      "28 [u'inception_4a_5x5/Conv2D']\n",
      "29 [u'inception_4a_pool_proj/Conv2D']\n",
      "30 [u'inception_4a_output']\n",
      "31 [u'inception_4b_pool']\n",
      "32 [u'inception_4b_1x1/Conv2D']\n",
      "33 [u'inception_4b_3x3_reduce/Conv2D']\n",
      "34 [u'inception_4b_3x3/Conv2D']\n",
      "35 [u'inception_4b_5x5_reduce/Conv2D']\n",
      "36 [u'inception_4b_5x5/Conv2D']\n",
      "37 [u'inception_4b_pool_proj/Conv2D']\n",
      "38 [u'inception_4b_output']\n",
      "39 [u'inception_4c_pool']\n",
      "40 [u'inception_4c_1x1/Conv2D']\n",
      "41 [u'inception_4c_3x3_reduce/Conv2D']\n",
      "42 [u'inception_4c_3x3/Conv2D']\n",
      "43 [u'inception_4c_5x5_reduce/Conv2D']\n",
      "44 [u'inception_4c_5x5/Conv2D']\n",
      "45 [u'inception_4c_pool_proj/Conv2D']\n",
      "46 [u'inception_4c_output']\n",
      "47 [u'inception_4d_pool']\n",
      "48 [u'inception_4d_1x1/Conv2D']\n",
      "49 [u'inception_4d_3x3_reduce/Conv2D']\n",
      "50 [u'inception_4d_3x3/Conv2D']\n",
      "51 [u'inception_4d_5x5_reduce/Conv2D']\n",
      "52 [u'inception_4d_5x5/Conv2D']\n",
      "53 [u'inception_4d_pool_proj/Conv2D']\n",
      "54 [u'inception_4d_output']\n",
      "55 [u'inception_4e_pool']\n",
      "56 [u'inception_4e_1x1/Conv2D']\n",
      "57 [u'inception_4e_3x3_reduce/Conv2D']\n",
      "58 [u'inception_4e_3x3/Conv2D']\n",
      "59 [u'inception_4e_5x5_reduce/Conv2D']\n",
      "60 [u'inception_4e_5x5/Conv2D']\n",
      "61 [u'inception_4e_pool_proj/Conv2D']\n",
      "62 [u'inception_4e_output']\n",
      "63 [u'pool4_3x3_s2']\n",
      "64 [u'inception_5a_pool']\n",
      "65 [u'inception_5a_1x1/Conv2D']\n",
      "66 [u'inception_5a_3x3_reduce/Conv2D']\n",
      "67 [u'inception_5a_3x3/Conv2D']\n",
      "68 [u'inception_5a_5x5_reduce/Conv2D']\n",
      "69 [u'inception_5a_5x5/Conv2D']\n",
      "70 [u'inception_5a_pool_proj/Conv2D']\n",
      "71 [u'inception_5a_output']\n",
      "72 [u'inception_5b_pool']\n",
      "73 [u'inception_5b_1x1/Conv2D']\n",
      "74 [u'inception_5b_3x3_reduce/Conv2D']\n",
      "75 [u'inception_5b_3x3/Conv2D']\n",
      "76 [u'inception_5b_5x5_reduce/Conv2D']\n",
      "77 [u'inception_5b_5x5/Conv2D']\n",
      "78 [u'inception_5b_pool_proj/Conv2D']\n",
      "79 [u'inception_5b_output']\n",
      "80 [u'pool5_7x7_s1']\n",
      "81 [u'loss3_classifier/Reshape']\n",
      "82 [u'loss3_classifier/loss3_classifier/MatMul']\n",
      "83 [u'prob']\n",
      "#######################\n",
      "**************************************************\n",
      "* Graph Manipulations\n",
      "**************************************************\n",
      "**************************************************\n",
      "* Graph weight manipulation\n",
      "**************************************************\n",
      "Schedule \n",
      "\n",
      "0 0 name data type Placeholder fpga False bottoms None - \n",
      "1 1 name conv1_7x7_s2/Conv2D type Convolution fpga True bottoms [u'data'] - \n",
      "2 2 name pool1_3x3_s2 type Pooling fpga True bottoms [u'conv1_7x7_s2/Conv2D'] - \n",
      "3 3 name conv2_3x3_reduce/Conv2D type Convolution fpga True bottoms [u'pool1_3x3_s2'] - \n",
      "4 4 name conv2_3x3/Conv2D type Convolution fpga True bottoms [u'conv2_3x3_reduce/Conv2D'] - \n",
      "5 5 name pool2_3x3_s2 type Pooling fpga True bottoms [u'conv2_3x3/Conv2D'] - \n",
      "6 6 name inception_3a_pool type Pooling fpga True bottoms [u'pool2_3x3_s2'] - \n",
      "7 7 name inception_3a_1x1/Conv2D type Convolution fpga True bottoms [u'pool2_3x3_s2'] - \n",
      "8 8 name inception_3a_3x3_reduce/Conv2D type Convolution fpga True bottoms [u'pool2_3x3_s2'] - \n",
      "9 9 name inception_3a_3x3/Conv2D type Convolution fpga True bottoms [u'inception_3a_3x3_reduce/Conv2D'] - \n",
      "10 10 name inception_3a_5x5_reduce/Conv2D type Convolution fpga True bottoms [u'pool2_3x3_s2'] - \n",
      "11 11 name inception_3a_5x5/Conv2D type Convolution fpga True bottoms [u'inception_3a_5x5_reduce/Conv2D'] - \n",
      "12 12 name inception_3a_pool_proj/Conv2D type Convolution fpga True bottoms [u'inception_3a_pool'] - \n",
      "13 13 name inception_3a_output type Concat fpga True bottoms [u'inception_3a_1x1/Conv2D', u'inception_3a_3x3/Conv2D', u'inception_3a_5x5/Conv2D', u'inception_3a_pool_proj/Conv2D'] - \n",
      "14 14 name inception_3b_pool type Pooling fpga True bottoms [u'inception_3a_output'] - \n",
      "15 15 name inception_3b_1x1/Conv2D type Convolution fpga True bottoms [u'inception_3a_output'] - \n",
      "16 16 name inception_3b_3x3_reduce/Conv2D type Convolution fpga True bottoms [u'inception_3a_output'] - \n",
      "17 17 name inception_3b_3x3/Conv2D type Convolution fpga True bottoms [u'inception_3b_3x3_reduce/Conv2D'] - \n",
      "18 18 name inception_3b_5x5_reduce/Conv2D type Convolution fpga True bottoms [u'inception_3a_output'] - \n",
      "19 19 name inception_3b_5x5/Conv2D type Convolution fpga True bottoms [u'inception_3b_5x5_reduce/Conv2D'] - \n",
      "20 20 name inception_3b_pool_proj/Conv2D type Convolution fpga True bottoms [u'inception_3b_pool'] - \n",
      "21 21 name inception_3b_output type Concat fpga True bottoms [u'inception_3b_1x1/Conv2D', u'inception_3b_3x3/Conv2D', u'inception_3b_5x5/Conv2D', u'inception_3b_pool_proj/Conv2D'] - \n",
      "22 22 name pool3_3x3_s2 type Pooling fpga True bottoms [u'inception_3b_output'] - \n",
      "23 23 name inception_4a_pool type Pooling fpga True bottoms [u'pool3_3x3_s2'] - \n",
      "24 24 name inception_4a_1x1/Conv2D type Convolution fpga True bottoms [u'pool3_3x3_s2'] - \n",
      "25 25 name inception_4a_3x3_reduce/Conv2D type Convolution fpga True bottoms [u'pool3_3x3_s2'] - \n",
      "26 26 name inception_4a_3x3/Conv2D type Convolution fpga True bottoms [u'inception_4a_3x3_reduce/Conv2D'] - \n",
      "27 27 name inception_4a_5x5_reduce/Conv2D type Convolution fpga True bottoms [u'pool3_3x3_s2'] - \n",
      "28 28 name inception_4a_5x5/Conv2D type Convolution fpga True bottoms [u'inception_4a_5x5_reduce/Conv2D'] - \n",
      "29 29 name inception_4a_pool_proj/Conv2D type Convolution fpga True bottoms [u'inception_4a_pool'] - \n",
      "30 30 name inception_4a_output type Concat fpga True bottoms [u'inception_4a_1x1/Conv2D', u'inception_4a_3x3/Conv2D', u'inception_4a_5x5/Conv2D', u'inception_4a_pool_proj/Conv2D'] - \n",
      "31 31 name inception_4b_pool type Pooling fpga True bottoms [u'inception_4a_output'] - \n",
      "32 32 name inception_4b_1x1/Conv2D type Convolution fpga True bottoms [u'inception_4a_output'] - \n",
      "33 33 name inception_4b_3x3_reduce/Conv2D type Convolution fpga True bottoms [u'inception_4a_output'] - \n",
      "34 34 name inception_4b_3x3/Conv2D type Convolution fpga True bottoms [u'inception_4b_3x3_reduce/Conv2D'] - \n",
      "35 35 name inception_4b_5x5_reduce/Conv2D type Convolution fpga True bottoms [u'inception_4a_output'] - \n",
      "36 36 name inception_4b_5x5/Conv2D type Convolution fpga True bottoms [u'inception_4b_5x5_reduce/Conv2D'] - \n",
      "37 37 name inception_4b_pool_proj/Conv2D type Convolution fpga True bottoms [u'inception_4b_pool'] - \n",
      "38 38 name inception_4b_output type Concat fpga True bottoms [u'inception_4b_1x1/Conv2D', u'inception_4b_3x3/Conv2D', u'inception_4b_5x5/Conv2D', u'inception_4b_pool_proj/Conv2D'] - \n",
      "39 39 name inception_4c_pool type Pooling fpga True bottoms [u'inception_4b_output'] - \n",
      "40 40 name inception_4c_1x1/Conv2D type Convolution fpga True bottoms [u'inception_4b_output'] - \n",
      "41 41 name inception_4c_3x3_reduce/Conv2D type Convolution fpga True bottoms [u'inception_4b_output'] - \n",
      "42 42 name inception_4c_3x3/Conv2D type Convolution fpga True bottoms [u'inception_4c_3x3_reduce/Conv2D'] - \n",
      "43 43 name inception_4c_5x5_reduce/Conv2D type Convolution fpga True bottoms [u'inception_4b_output'] - \n",
      "44 44 name inception_4c_5x5/Conv2D type Convolution fpga True bottoms [u'inception_4c_5x5_reduce/Conv2D'] - \n",
      "45 45 name inception_4c_pool_proj/Conv2D type Convolution fpga True bottoms [u'inception_4c_pool'] - \n",
      "46 46 name inception_4c_output type Concat fpga True bottoms [u'inception_4c_1x1/Conv2D', u'inception_4c_3x3/Conv2D', u'inception_4c_5x5/Conv2D', u'inception_4c_pool_proj/Conv2D'] - \n",
      "47 47 name inception_4d_pool type Pooling fpga True bottoms [u'inception_4c_output'] - \n",
      "48 48 name inception_4d_1x1/Conv2D type Convolution fpga True bottoms [u'inception_4c_output'] - \n",
      "49 49 name inception_4d_3x3_reduce/Conv2D type Convolution fpga True bottoms [u'inception_4c_output'] - \n",
      "50 50 name inception_4d_3x3/Conv2D type Convolution fpga True bottoms [u'inception_4d_3x3_reduce/Conv2D'] - \n",
      "51 51 name inception_4d_5x5_reduce/Conv2D type Convolution fpga True bottoms [u'inception_4c_output'] - \n",
      "52 52 name inception_4d_5x5/Conv2D type Convolution fpga True bottoms [u'inception_4d_5x5_reduce/Conv2D'] - \n",
      "53 53 name inception_4d_pool_proj/Conv2D type Convolution fpga True bottoms [u'inception_4d_pool'] - \n",
      "54 54 name inception_4d_output type Concat fpga True bottoms [u'inception_4d_1x1/Conv2D', u'inception_4d_3x3/Conv2D', u'inception_4d_5x5/Conv2D', u'inception_4d_pool_proj/Conv2D'] - \n",
      "55 55 name inception_4e_pool type Pooling fpga True bottoms [u'inception_4d_output'] - \n",
      "56 56 name inception_4e_1x1/Conv2D type Convolution fpga True bottoms [u'inception_4d_output'] - \n",
      "57 57 name inception_4e_3x3_reduce/Conv2D type Convolution fpga True bottoms [u'inception_4d_output'] - \n",
      "58 58 name inception_4e_3x3/Conv2D type Convolution fpga True bottoms [u'inception_4e_3x3_reduce/Conv2D'] - \n",
      "59 59 name inception_4e_5x5_reduce/Conv2D type Convolution fpga True bottoms [u'inception_4d_output'] - \n",
      "60 60 name inception_4e_5x5/Conv2D type Convolution fpga True bottoms [u'inception_4e_5x5_reduce/Conv2D'] - \n",
      "61 61 name inception_4e_pool_proj/Conv2D type Convolution fpga True bottoms [u'inception_4e_pool'] - \n",
      "62 62 name inception_4e_output type Concat fpga True bottoms [u'inception_4e_1x1/Conv2D', u'inception_4e_3x3/Conv2D', u'inception_4e_5x5/Conv2D', u'inception_4e_pool_proj/Conv2D'] - \n",
      "63 63 name pool4_3x3_s2 type Pooling fpga True bottoms [u'inception_4e_output'] - \n",
      "64 64 name inception_5a_pool type Pooling fpga True bottoms [u'pool4_3x3_s2'] - \n",
      "65 65 name inception_5a_1x1/Conv2D type Convolution fpga True bottoms [u'pool4_3x3_s2'] - \n",
      "66 66 name inception_5a_3x3_reduce/Conv2D type Convolution fpga True bottoms [u'pool4_3x3_s2'] - \n",
      "67 67 name inception_5a_3x3/Conv2D type Convolution fpga True bottoms [u'inception_5a_3x3_reduce/Conv2D'] - \n",
      "68 68 name inception_5a_5x5_reduce/Conv2D type Convolution fpga True bottoms [u'pool4_3x3_s2'] - \n",
      "69 69 name inception_5a_5x5/Conv2D type Convolution fpga True bottoms [u'inception_5a_5x5_reduce/Conv2D'] - \n",
      "70 70 name inception_5a_pool_proj/Conv2D type Convolution fpga True bottoms [u'inception_5a_pool'] - \n",
      "71 71 name inception_5a_output type Concat fpga True bottoms [u'inception_5a_1x1/Conv2D', u'inception_5a_3x3/Conv2D', u'inception_5a_5x5/Conv2D', u'inception_5a_pool_proj/Conv2D'] - \n",
      "72 72 name inception_5b_pool type Pooling fpga True bottoms [u'inception_5a_output'] - \n",
      "73 73 name inception_5b_1x1/Conv2D type Convolution fpga True bottoms [u'inception_5a_output'] - \n",
      "74 74 name inception_5b_3x3_reduce/Conv2D type Convolution fpga True bottoms [u'inception_5a_output'] - \n",
      "75 75 name inception_5b_3x3/Conv2D type Convolution fpga True bottoms [u'inception_5b_3x3_reduce/Conv2D'] - \n",
      "76 76 name inception_5b_5x5_reduce/Conv2D type Convolution fpga True bottoms [u'inception_5a_output'] - \n",
      "77 77 name inception_5b_5x5/Conv2D type Convolution fpga True bottoms [u'inception_5b_5x5_reduce/Conv2D'] - \n",
      "78 78 name inception_5b_pool_proj/Conv2D type Convolution fpga True bottoms [u'inception_5b_pool'] - \n",
      "79 79 name inception_5b_output type Concat fpga True bottoms [u'inception_5b_1x1/Conv2D', u'inception_5b_3x3/Conv2D', u'inception_5b_5x5/Conv2D', u'inception_5b_pool_proj/Conv2D'] - \n",
      "80 80 name pool5_7x7_s1 type Pooling fpga True bottoms [u'inception_5b_output'] - \n",
      "81 81 name loss3_classifier/Reshape type Reshape fpga False bottoms [u'pool5_7x7_s1'] - \n",
      "82 82 name loss3_classifier/loss3_classifier/MatMul type InnerProduct fpga True bottoms [u'loss3_classifier/Reshape'] - \n",
      "83 83 name prob type Softmax fpga False bottoms [u'loss3_classifier/loss3_classifier/MatMul'] - \n",
      "####################################\n",
      "**************************************************\n",
      "* COMPUTING MEMORY REQUIREMENTS\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Memory __________\n",
      "17 [u'inception_3b_3x3/Conv2D'] size:3440640.0 remap:[] data movement:[]\n",
      "17\tinception_3b_3x3_reduce/Conv2D_blob M[0,458752] Z=458752 F=[17] B=[16] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=128, height=28, width=28)\n",
      "17\tinception_3a_output_blob M[0,917504] Z=917504 F=[14, 15, 16, 18] B=[13] E=[] S=['replace_layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=256, height=28, width=28)\n",
      "17\tinception_3b_pool_blob M[0,917504] Z=917504 F=[20] B=[14] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=256, height=28, width=28)\n",
      "17\tinception_3b_1x1/Conv2D_blob M[0,458752] Z=458752 F=[21] B=[15] E=[] S=['layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=128, height=28, width=28)\n",
      "17\tinception_3b_3x3/Conv2D_blob M[0,688128] Z=688128 F=[21] B=[17] E=[] S=['layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=192, height=28, width=28)\n",
      "MAX  17\n",
      "TOP 5\n",
      "__________\n",
      "17 [u'inception_3b_3x3/Conv2D'] size:3440640.0 remap:[] data movement:[]\n",
      "17\tinception_3b_3x3_reduce/Conv2D_blob M[0,458752] Z=458752 F=[17] B=[16] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=128, height=28, width=28)\n",
      "17\tinception_3a_output_blob M[0,917504] Z=917504 F=[14, 15, 16, 18] B=[13] E=[] S=['replace_layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=256, height=28, width=28)\n",
      "17\tinception_3b_pool_blob M[0,917504] Z=917504 F=[20] B=[14] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=256, height=28, width=28)\n",
      "17\tinception_3b_1x1/Conv2D_blob M[0,458752] Z=458752 F=[21] B=[15] E=[] S=['layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=128, height=28, width=28)\n",
      "17\tinception_3b_3x3/Conv2D_blob M[0,688128] Z=688128 F=[21] B=[17] E=[] S=['layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=192, height=28, width=28)\n",
      "__________\n",
      "58 [u'inception_4e_3x3/Conv2D'] size:3211264.0 remap:[] data movement:[]\n",
      "58\tinception_4e_3x3_reduce/Conv2D_blob M[0,286720] Z=286720 F=[58] B=[57] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=160, height=14, width=14)\n",
      "58\tinception_4d_output_blob M[0,946176] Z=946176 F=[55, 56, 57, 59] B=[54] E=[] S=['replace_layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=528, height=14, width=14)\n",
      "58\tinception_4e_pool_blob M[0,946176] Z=946176 F=[61] B=[55] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=528, height=14, width=14)\n",
      "58\tinception_4e_1x1/Conv2D_blob M[0,458752] Z=458752 F=[62] B=[56] E=[] S=['layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=256, height=14, width=14)\n",
      "58\tinception_4e_3x3/Conv2D_blob M[0,573440] Z=573440 F=[62] B=[58] E=[] S=['layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=320, height=14, width=14)\n",
      "__________\n",
      "18 [u'inception_3b_5x5_reduce/Conv2D'] size:3096576.0 remap:[] data movement:[]\n",
      "18\tinception_3a_output_blob M[0,917504] Z=917504 F=[14, 15, 16, 18] B=[13] E=[] S=['replace_layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=256, height=28, width=28)\n",
      "18\tinception_3b_5x5_reduce/Conv2D_blob M[0,114688] Z=114688 F=[19] B=[18] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=32, height=28, width=28)\n",
      "18\tinception_3b_pool_blob M[0,917504] Z=917504 F=[20] B=[14] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=256, height=28, width=28)\n",
      "18\tinception_3b_1x1/Conv2D_blob M[0,458752] Z=458752 F=[21] B=[15] E=[] S=['layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=128, height=28, width=28)\n",
      "18\tinception_3b_3x3/Conv2D_blob M[0,688128] Z=688128 F=[21] B=[17] E=[] S=['layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=192, height=28, width=28)\n",
      "__________\n",
      "59 [u'inception_4e_5x5_reduce/Conv2D'] size:2981888.0 remap:[] data movement:[]\n",
      "59\tinception_4d_output_blob M[0,946176] Z=946176 F=[55, 56, 57, 59] B=[54] E=[] S=['replace_layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=528, height=14, width=14)\n",
      "59\tinception_4e_5x5_reduce/Conv2D_blob M[0,57344] Z=57344 F=[60] B=[59] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=32, height=14, width=14)\n",
      "59\tinception_4e_pool_blob M[0,946176] Z=946176 F=[61] B=[55] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=528, height=14, width=14)\n",
      "59\tinception_4e_1x1/Conv2D_blob M[0,458752] Z=458752 F=[62] B=[56] E=[] S=['layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=256, height=14, width=14)\n",
      "59\tinception_4e_3x3/Conv2D_blob M[0,573440] Z=573440 F=[62] B=[58] E=[] S=['layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=320, height=14, width=14)\n",
      "__________\n",
      "50 [u'inception_4d_3x3/Conv2D'] size:2809856.0 remap:[] data movement:[]\n",
      "50\tinception_4d_3x3_reduce/Conv2D_blob M[0,258048] Z=258048 F=[50] B=[49] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=144, height=14, width=14)\n",
      "50\tinception_4c_output_blob M[0,917504] Z=917504 F=[47, 48, 49, 51] B=[46] E=[] S=['replace_layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=512, height=14, width=14)\n",
      "50\tinception_4d_pool_blob M[0,917504] Z=917504 F=[53] B=[47] E=[] S=['layer'] [] L=-1 T=SizeType(batches=1, channels=512, height=14, width=14)\n",
      "50\tinception_4d_3x3/Conv2D_blob M[0,516096] Z=516096 F=[54] B=[50] E=[] S=['layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=288, height=14, width=14)\n",
      "50\tinception_4d_1x1/Conv2D_blob M[0,200704] Z=200704 F=[54] B=[48] E=[] S=['layer'] ['concat'] L=-1 T=SizeType(batches=1, channels=112, height=14, width=14)\n",
      "VERSION [2]\n",
      "**************************************************\n",
      "* ALLOCATING DYNAMIC MEMORY SCHEDULE\n",
      "**************************************************\n",
      "Allocating Memory all\n",
      "\n",
      "##########\n",
      "One Slice, One Vision presents: \n",
      "DDR The_Master_of_the_brains\n",
      "\t self.alignment         64\n",
      "\t self.FREE              {(0, 268435456): MemoryAllocation(start=0, end=268435456, size=268435456, extra=[], strategy=[], layout=-1, timestamp=-1, slice=-1, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False)}\n",
      "\t self.size              268435456\n",
      "\t self.timestamp         0\n",
      "\t self.slice             -1\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.batches             4\n",
      "\t self.dsp 56\n",
      "==========\n",
      "DSP pinky\n",
      "\t self.slice               0\n",
      "\t self.rule                rule2\n",
      "\t self.dsp                 56\n",
      "\t self.bytesperpixels      2\n",
      "\t self.precision           16\n",
      "\t self.column              16\n",
      "\t self.minimum_replication 16\n",
      "\t self.batches             4\n",
      "-------\n",
      "AM for pinky\n",
      "\t self.alignment         56\n",
      "\t self.FREE              {(0, 5242880): MemoryAllocation(start=0, end=5242880, size=5242880, extra=[], strategy=[], layout=-1, timestamp=-1, slice=0, shapes=None, replication=Replication(full_sect_num=0, repl_sect_num=0, repl_unit_num=0, repl_unit_width=0, channels_division=0), written=False)}\n",
      "\t self.size              5242880\n",
      "\t self.timestamp         278\n",
      "\t self.slice             0\n",
      "\t self.bytesperpixels    2\n",
      "\t self.strategies_       ['bysize', 'bottom', 'top', 'tops', 'bottle', 'bottles', 'xXx', 'shuffle', 'flip']\n",
      "\t self.rules              rule2\n",
      "\t self.batches             4\n",
      "\t self.replications       [48, 32]\n",
      "\t self.channels_per_banks 8\n",
      "['XNAvgPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "=['XNGather', 'id XNOp uram_dest ddr_src input_w input_h input_chan a0 b1 c1 start_row end_row ']\n",
      "=['XNDeconv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNMaxPool', 'id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt ']\n",
      "=['XNScatter', 'id XNOp uram_src ddr_dest input_w input_h input_chan a0 b1 c1 start_row end_row ']\n",
      "=['XNUpload', 'id XNOp inaddr insize inchan']\n",
      "=['XNEltwise', 'id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt ']\n",
      "=['XNConv', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt ']\n",
      "=['XNConvP', 'id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h']\n",
      "##########\n",
      "\n",
      "Reset Memory\n",
      "Trying strategy bysize NO DDR:\n",
      "Done Strategy bysize NO DDR\n",
      "Done schedule 84 STEPS\n",
      "**************************************************\n",
      "* GENERATING OUTPUT REPORTS\n",
      "**************************************************\n",
      "schedule_and_parallelism\n",
      "Minimum Memory 80 [u'pool5_7x7_s1'] 5242880.0\n",
      "pool5_7x7_s1_blob M[0,131072] Z=131072 F=[81] B=[80] E=[1] S=['layer'] [] L=0 T=SizeType(batches=1, channels=1024, height=1, width=1)\n",
      "inception_5b_output_blob M[4325376,5242880] Z=917504 F=[80] B=[79] E=[1] S=['replace_layer'] ['concat'] L=0 T=SizeType(batches=1, channels=1024, height=7, width=7)\n",
      "**************************************************\n",
      "* GENERATING OUTPUT FILES\n",
      "**************************************************\n",
      "XDNN Command file: work/fpga.cmds\n",
      "XDNN JSON Report file: work/fpga.cmds.json\n",
      "work\n",
      "Path to generatefile exists...\n",
      "***** Inst JSON\n",
      "<class 'argparse.Namespace'>\n",
      "OUTPUT REPORT:\n",
      "Unsupported Layers: 4\n",
      "0) loss3_classifier/loss3_classifier/MatMul\n",
      "\tAttributes: (u'## 83 XNInner loss3_classifier/loss3_classifier/MatMul 16 26 2 0x20000 1 1 0x0 1 1', u'loss3_classifier/loss3_classifier/MatMul: type=InnerProduct, sizes=None, shapes=None, sched 82 Kernel None Strides None Padding None  NO VALID CODE  ')\n",
      "1) data\n",
      "\tAttributes: (u\"# LAYER data [u'Placeholder'] ['layer']\", u'data: type=Placeholder, sizes=None, shapes=None, sched 0 Kernel None Strides None Padding None  NO VALID CODE  ')\n",
      "2) prob\n",
      "\tAttributes: (u\"# LAYER prob [u'Softmax'] ['layer']\", u'prob: type=Softmax, sizes=None, shapes=None, sched 83 Kernel None Strides None Padding None  NO VALID CODE  ')\n",
      "3) loss3_classifier/Reshape\n",
      "\tAttributes: (u'# LAYER \"loss3_classifier/Reshape\" [\\'Reshape\\'] [\\'layer\\']', u'loss3_classifier/Reshape: type=Reshape, sizes=None, shapes=None, sched 81 Kernel None Strides None Padding None  NO VALID CODE  ')\n",
      "***** Inst JSON Done\n",
      "***** Inst FILE\n",
      "***** Inst FILE OUT\n",
      "***** Inst COLLECT\n",
      "***** COLLECT CODES 90\n",
      "# template XNAvgPool id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h fcmode inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt \n",
      "# template XNGather id XNOp uram_dest ddr_src input_w input_h input_chan a0 b1 c1 start_row end_row \n",
      "# template XNDeconv id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt \n",
      "# template XNMaxPool id XNOp name kernel_w kernel_h  strides_w strides_h paddings_w paddings_h  inaddr insize_w insize_h inchan outaddr outsize_w outsize_h Bypass_Perf_Opt \n",
      "# template XNScatter id XNOp uram_src ddr_dest input_w input_h input_chan a0 b1 c1 start_row end_row \n",
      "# template XNUpload id XNOp inaddr insize inchan\n",
      "# template XNEltwise id XNOp name add bn relu inaddrA inaddrB insize_w insize_h inchan outaddr Bypass_Perf_Opt \n",
      "# template XNConv id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt \n",
      "# template XNConvP id XNOp name kernel_w kernel_h strides_w strides_h padding_w padding_h dilation_w dilation_h preshift scale postshift relu bias inaddr insize_w insize_h inchan outaddr outsize_w outsize_h  outchan Bypass_Perf_Opt  pool_kernel_w pool_kernel_h pool_strides_w pool_strides_h pool_paddings_w pool_paddings_h pool_fcmode pool_inaddr pool_insize_w pool_insize_h pool_inchan pool_outaddr pool_outsize_w pool_outsize_h\n",
      "2 XNConv conv1_7x7_s2/Conv2D 7 7 2 2 3 3 1 1 16 26 2 1 1 0x0 224 224 3 0x70000 112 112 64 0\n",
      "3 XNMaxPool pool1_3x3_s2 3 3 2 2 0 0 0x70000 112 112 64 0x0 56 56 0\n",
      "4 XNConv conv2_3x3_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x0 56 56 64 0x70000 56 56 64 0\n",
      "5 XNConv conv2_3x3/Conv2D 3 3 1 1 1 1 1 1 16 26 2 1 1 0x70000 56 56 64 0xe0000 56 56 192 0\n",
      "6 XNMaxPool pool2_3x3_s2 3 3 2 2 0 0 0xe0000 56 56 192 0x0 28 28 0\n",
      "7 XNMaxPool inception_3a_pool 3 3 1 1 1 1 0x0 28 28 192 0xa8000 28 28 0\n",
      "8 XNConv inception_3a_1x1/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x0 28 28 192 0x420000 28 28 64 0\n",
      "9 XNConv inception_3a_3x3_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x0 28 28 192 0x150000 28 28 96 0\n",
      "10 XNConv inception_3a_3x3/Conv2D 3 3 1 1 1 1 1 1 16 26 2 1 1 0x150000 28 28 96 0x458000 28 28 128 0\n",
      "11 XNConv inception_3a_5x5_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x0 28 28 192 0x150000 28 28 16 0\n",
      "12 XNConv inception_3a_5x5/Conv2D 5 5 1 1 2 2 1 1 16 26 2 1 1 0x150000 28 28 16 0x4c8000 28 28 32 0\n",
      "13 XNConv inception_3a_pool_proj/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0xa8000 28 28 192 0x4e4000 28 28 32 0\n",
      "# 14 XNConcat inception_3a_output  0x420000 0x500000 917504 \n",
      "15 XNMaxPool inception_3b_pool 3 3 1 1 1 1 0x420000 28 28 256 0x0 28 28 0\n",
      "16 XNConv inception_3b_1x1/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x420000 28 28 256 0x27c000 28 28 128 0\n",
      "17 XNConv inception_3b_3x3_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x420000 28 28 256 0xe0000 28 28 128 0\n",
      "18 XNConv inception_3b_3x3/Conv2D 3 3 1 1 1 1 1 1 16 26 2 1 1 0xe0000 28 28 128 0x2ec000 28 28 192 0\n",
      "19 XNConv inception_3b_5x5_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x420000 28 28 256 0xe0000 28 28 32 0\n",
      "20 XNConv inception_3b_5x5/Conv2D 5 5 1 1 2 2 1 1 16 26 2 1 1 0xe0000 28 28 32 0x394000 28 28 96 0\n",
      "21 XNConv inception_3b_pool_proj/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x0 28 28 256 0x3e8000 28 28 64 0\n",
      "# 22 XNConcat inception_3b_output  0x27c000 0x420000 1720320 \n",
      "23 XNMaxPool pool3_3x3_s2 3 3 2 2 0 0 0x27c000 28 28 480 0x420000 14 14 0\n",
      "24 XNMaxPool inception_4a_pool 3 3 1 1 1 1 0x420000 14 14 480 0x0 14 14 0\n",
      "25 XNConv inception_4a_1x1/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x420000 14 14 480 0x340000 14 14 192 0\n",
      "26 XNConv inception_4a_3x3_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x420000 14 14 480 0xd2000 14 14 96 0\n",
      "27 XNConv inception_4a_3x3/Conv2D 3 3 1 1 1 1 1 1 16 26 2 1 1 0xd2000 14 14 96 0x394000 14 14 208 0\n",
      "28 XNConv inception_4a_5x5_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x420000 14 14 480 0x4f2000 14 14 16 0\n",
      "29 XNConv inception_4a_5x5/Conv2D 5 5 1 1 2 2 1 1 16 26 2 1 1 0x4f2000 14 14 16 0x3ef000 14 14 48 0\n",
      "30 XNConv inception_4a_pool_proj/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x0 14 14 480 0x404000 14 14 64 0\n",
      "# 31 XNConcat inception_4a_output  0x340000 0x420000 917504 \n",
      "32 XNMaxPool inception_4b_pool 3 3 1 1 1 1 0x340000 14 14 512 0x420000 14 14 0\n",
      "33 XNConv inception_4b_1x1/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x340000 14 14 512 0x260000 14 14 160 0\n",
      "34 XNConv inception_4b_3x3_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x340000 14 14 512 0x0 14 14 112 0\n",
      "35 XNConv inception_4b_3x3/Conv2D 3 3 1 1 1 1 1 1 16 26 2 1 1 0x0 14 14 112 0x2a6000 14 14 224 0\n",
      "36 XNConv inception_4b_5x5_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x340000 14 14 512 0x0 14 14 24 0\n",
      "37 XNConv inception_4b_5x5/Conv2D 5 5 1 1 2 2 1 1 16 26 2 1 1 0x0 14 14 24 0x308000 14 14 64 0\n",
      "38 XNConv inception_4b_pool_proj/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x420000 14 14 512 0x324000 14 14 64 0\n",
      "# 39 XNConcat inception_4b_output  0x260000 0x340000 917504 \n",
      "40 XNMaxPool inception_4c_pool 3 3 1 1 1 1 0x260000 14 14 512 0x340000 14 14 0\n",
      "41 XNConv inception_4c_1x1/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x260000 14 14 512 0x420000 14 14 128 0\n",
      "42 XNConv inception_4c_3x3_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x260000 14 14 512 0x0 14 14 128 0\n",
      "43 XNConv inception_4c_3x3/Conv2D 3 3 1 1 1 1 1 1 16 26 2 1 1 0x0 14 14 128 0x458000 14 14 256 0\n",
      "44 XNConv inception_4c_5x5_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x260000 14 14 512 0x0 14 14 24 0\n",
      "45 XNConv inception_4c_5x5/Conv2D 5 5 1 1 2 2 1 1 16 26 2 1 1 0x0 14 14 24 0x4c8000 14 14 64 0\n",
      "46 XNConv inception_4c_pool_proj/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x340000 14 14 512 0x4e4000 14 14 64 0\n",
      "# 47 XNConcat inception_4c_output  0x420000 0x500000 917504 \n",
      "48 XNMaxPool inception_4d_pool 3 3 1 1 1 1 0x420000 14 14 512 0x0 14 14 0\n",
      "49 XNConv inception_4d_1x1/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x420000 14 14 512 0x339000 14 14 112 0\n",
      "50 XNConv inception_4d_3x3_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x420000 14 14 512 0xe0000 14 14 144 0\n",
      "51 XNConv inception_4d_3x3/Conv2D 3 3 1 1 1 1 1 1 16 26 2 1 1 0xe0000 14 14 144 0x36a000 14 14 288 0\n",
      "52 XNConv inception_4d_5x5_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x420000 14 14 512 0xe0000 14 14 32 0\n",
      "53 XNConv inception_4d_5x5/Conv2D 5 5 1 1 2 2 1 1 16 26 2 1 1 0xe0000 14 14 32 0x3e8000 14 14 64 0\n",
      "54 XNConv inception_4d_pool_proj/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x0 14 14 512 0x404000 14 14 64 0\n",
      "# 55 XNConcat inception_4d_output  0x339000 0x420000 946176 \n",
      "56 XNMaxPool inception_4e_pool 3 3 1 1 1 1 0x339000 14 14 528 0x0 14 14 0\n",
      "57 XNConv inception_4e_1x1/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x339000 14 14 528 0x1cd000 14 14 256 0\n",
      "58 XNConv inception_4e_3x3_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x339000 14 14 528 0x420000 14 14 160 0\n",
      "59 XNConv inception_4e_3x3/Conv2D 3 3 1 1 1 1 1 1 16 26 2 1 1 0x420000 14 14 160 0x23d000 14 14 320 0\n",
      "60 XNConv inception_4e_5x5_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x339000 14 14 528 0x420000 14 14 32 0\n",
      "61 XNConv inception_4e_5x5/Conv2D 5 5 1 1 2 2 1 1 16 26 2 1 1 0x420000 14 14 32 0x2c9000 14 14 128 0\n",
      "62 XNConv inception_4e_pool_proj/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x0 14 14 528 0x301000 14 14 128 0\n",
      "# 63 XNConcat inception_4e_output  0x1cd000 0x339000 1490944 \n",
      "64 XNMaxPool pool4_3x3_s2 3 3 2 2 0 0 0x1cd000 14 14 832 0x339000 7 7 0\n",
      "65 XNMaxPool inception_5a_pool 3 3 1 1 1 1 0x339000 7 7 832 0x3ef000 7 7 0\n",
      "66 XNConv inception_5a_1x1/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x339000 7 7 832 0x283000 7 7 256 0\n",
      "67 XNConv inception_5a_3x3_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x339000 7 7 832 0x4a5000 7 7 160 0\n",
      "68 XNConv inception_5a_3x3/Conv2D 3 3 1 1 1 1 1 1 16 26 2 1 1 0x4a5000 7 7 160 0x2bb000 7 7 320 0\n",
      "69 XNConv inception_5a_5x5_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x339000 7 7 832 0x4a5000 7 7 32 0\n",
      "70 XNConv inception_5a_5x5/Conv2D 5 5 1 1 2 2 1 1 16 26 2 1 1 0x4a5000 7 7 32 0x301000 7 7 128 0\n",
      "71 XNConv inception_5a_pool_proj/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x3ef000 7 7 832 0x31d000 7 7 128 0\n",
      "# 72 XNConcat inception_5a_output  0x283000 0x339000 745472 \n",
      "73 XNMaxPool inception_5b_pool 3 3 1 1 1 1 0x283000 7 7 832 0x339000 7 7 0\n",
      "74 XNConv inception_5b_1x1/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x283000 7 7 832 0x420000 7 7 384 0\n",
      "75 XNConv inception_5b_3x3_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x283000 7 7 832 0x3ef000 7 7 192 0\n",
      "76 XNConv inception_5b_3x3/Conv2D 3 3 1 1 1 1 1 1 16 26 2 1 1 0x3ef000 7 7 192 0x474000 7 7 384 0\n",
      "77 XNConv inception_5b_5x5_reduce/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x283000 7 7 832 0x3ef000 7 7 48 0\n",
      "78 XNConv inception_5b_5x5/Conv2D 5 5 1 1 2 2 1 1 16 26 2 1 1 0x3ef000 7 7 48 0x4c8000 7 7 128 0\n",
      "79 XNConv inception_5b_pool_proj/Conv2D 1 1 1 1 0 0 1 1 16 26 2 1 1 0x339000 7 7 832 0x4e4000 7 7 128 0\n",
      "# 80 XNConcat inception_5b_output  0x420000 0x500000 917504 \n",
      "81 XNAvgPool pool5_7x7_s1 7 7 1 1 0 0 0 0x420000 7 7 1024 0x0 1 1 0\n",
      "# ## 83 XNInner loss3_classifier/loss3_classifier/MatMul 16 26 2 0x20000 1 1 0x0 1 1 loss3_classifier/loss3_classifier/MatMul: type=InnerProduct, sizes=None, shapes=None, sched 82 Kernel None Strides None Padding None  NO VALID CODE  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling weights from: /home/centos/models/tensorflow/bvlc_googlenet_without_lrn/fp32/bvlc_googlenet_without_lrn_test.pb\n",
      "\n",
      "**************************************************\n",
      "* CLEANING PREVIOUS WEIGHTS:work/bvlc_googlenet_without_lrn_test.pb_data\n",
      "* wbq_size_0\n",
      "* fwbqb_0\n",
      "* fwbqb_bias_0\n",
      "* wbq_size_1\n",
      "* fwbqb_1\n",
      "* fwbqb_bias_1\n",
      "* wbq_size_2\n",
      "* fwbqb_2\n",
      "* fwbqb_bias_2\n",
      "* wbq_size_3\n",
      "* fwbqb_3\n",
      "* fwbqb_bias_3\n",
      "* wbq_size_4\n",
      "* fwbqb_4\n",
      "* fwbqb_bias_4\n",
      "* wbq_size_5\n",
      "* fwbqb_5\n",
      "* fwbqb_bias_5\n",
      "* wbq_size_6\n",
      "* fwbqb_6\n",
      "* fwbqb_bias_6\n",
      "* wbq_size_7\n",
      "* fwbqb_7\n",
      "* fwbqb_bias_7\n",
      "* wbq_size_8\n",
      "* fwbqb_8\n",
      "* fwbqb_bias_8\n",
      "* wbq_size_9\n",
      "* fwbqb_9\n",
      "* fwbqb_bias_9\n",
      "* wbq_size_10\n",
      "* fwbqb_10\n",
      "* fwbqb_bias_10\n",
      "* wbq_size_11\n",
      "* fwbqb_11\n",
      "* fwbqb_bias_11\n",
      "* wbq_size_12\n",
      "* fwbqb_12\n",
      "* fwbqb_bias_12\n",
      "* wbq_size_13\n",
      "* fwbqb_13\n",
      "* fwbqb_bias_13\n",
      "* wbq_size_14\n",
      "* fwbqb_14\n",
      "* fwbqb_bias_14\n",
      "* wbq_size_15\n",
      "* fwbqb_15\n",
      "* fwbqb_bias_15\n",
      "* wbq_size_16\n",
      "* fwbqb_16\n",
      "* fwbqb_bias_16\n",
      "* wbq_size_17\n",
      "* fwbqb_17\n",
      "* fwbqb_bias_17\n",
      "* wbq_size_18\n",
      "* fwbqb_18\n",
      "* fwbqb_bias_18\n",
      "* wbq_size_19\n",
      "* fwbqb_19\n",
      "* fwbqb_bias_19\n",
      "* wbq_size_20\n",
      "* fwbqb_20\n",
      "* fwbqb_bias_20\n",
      "* wbq_size_21\n",
      "* fwbqb_21\n",
      "* fwbqb_bias_21\n",
      "* wbq_size_22\n",
      "* fwbqb_22\n",
      "* fwbqb_bias_22\n",
      "* wbq_size_23\n",
      "* fwbqb_23\n",
      "* fwbqb_bias_23\n",
      "* wbq_size_24\n",
      "* fwbqb_24\n",
      "* fwbqb_bias_24\n",
      "* wbq_size_25\n",
      "* fwbqb_25\n",
      "* fwbqb_bias_25\n",
      "* wbq_size_26\n",
      "* fwbqb_26\n",
      "* fwbqb_bias_26\n",
      "* wbq_size_27\n",
      "* fwbqb_27\n",
      "* fwbqb_bias_27\n",
      "* wbq_size_28\n",
      "* fwbqb_28\n",
      "* fwbqb_bias_28\n",
      "* wbq_size_29\n",
      "* fwbqb_29\n",
      "* fwbqb_bias_29\n",
      "* wbq_size_30\n",
      "* fwbqb_30\n",
      "* fwbqb_bias_30\n",
      "* wbq_size_31\n",
      "* fwbqb_31\n",
      "* fwbqb_bias_31\n",
      "* wbq_size_32\n",
      "* fwbqb_32\n",
      "* fwbqb_bias_32\n",
      "* wbq_size_33\n",
      "* fwbqb_33\n",
      "* fwbqb_bias_33\n",
      "* wbq_size_34\n",
      "* fwbqb_34\n",
      "* fwbqb_bias_34\n",
      "* wbq_size_35\n",
      "* fwbqb_35\n",
      "* fwbqb_bias_35\n",
      "* wbq_size_36\n",
      "* fwbqb_36\n",
      "* fwbqb_bias_36\n",
      "* wbq_size_37\n",
      "* fwbqb_37\n",
      "* fwbqb_bias_37\n",
      "* wbq_size_38\n",
      "* fwbqb_38\n",
      "* fwbqb_bias_38\n",
      "* wbq_size_39\n",
      "* fwbqb_39\n",
      "* fwbqb_bias_39\n",
      "* wbq_size_40\n",
      "* fwbqb_40\n",
      "* fwbqb_bias_40\n",
      "* wbq_size_41\n",
      "* fwbqb_41\n",
      "* fwbqb_bias_41\n",
      "* wbq_size_42\n",
      "* fwbqb_42\n",
      "* fwbqb_bias_42\n",
      "* wbq_size_43\n",
      "* fwbqb_43\n",
      "* fwbqb_bias_43\n",
      "* wbq_size_44\n",
      "* fwbqb_44\n",
      "* fwbqb_bias_44\n",
      "* wbq_size_45\n",
      "* fwbqb_45\n",
      "* fwbqb_bias_45\n",
      "* wbq_size_46\n",
      "* fwbqb_46\n",
      "* fwbqb_bias_46\n",
      "* wbq_size_47\n",
      "* fwbqb_47\n",
      "* fwbqb_bias_47\n",
      "* wbq_size_48\n",
      "* fwbqb_48\n",
      "* fwbqb_bias_48\n",
      "* wbq_size_49\n",
      "* fwbqb_49\n",
      "* fwbqb_bias_49\n",
      "* wbq_size_50\n",
      "* fwbqb_50\n",
      "* fwbqb_bias_50\n",
      "* wbq_size_51\n",
      "* fwbqb_51\n",
      "* fwbqb_bias_51\n",
      "* wbq_size_52\n",
      "* fwbqb_52\n",
      "* fwbqb_bias_52\n",
      "* wbq_size_53\n",
      "* fwbqb_53\n",
      "* fwbqb_bias_53\n",
      "* wbq_size_54\n",
      "* fwbqb_54\n",
      "* fwbqb_bias_54\n",
      "* wbq_size_55\n",
      "* fwbqb_55\n",
      "* fwbqb_bias_55\n",
      "* wbq_size_56\n",
      "* fwbqb_56\n",
      "* fwbqb_bias_56\n",
      "* fc_57\n",
      "* fc_bias_57\n",
      "**************************************************\n",
      "Writing weights to directory: work/bvlc_googlenet_without_lrn_test.pb_data\n",
      "Processing schedule step 1/84\n",
      "\tLayer: data\n",
      "Processing schedule step 2/84\n",
      "\tLayer: conv1_7x7_s2/Conv2D\n",
      "Processing schedule step 3/84\n",
      "\tLayer: pool1_3x3_s2\n",
      "Processing schedule step 4/84\n",
      "\tLayer: conv2_3x3_reduce/Conv2D\n",
      "Processing schedule step 5/84\n",
      "\tLayer: conv2_3x3/Conv2D\n",
      "Processing schedule step 6/84\n",
      "\tLayer: pool2_3x3_s2\n",
      "Processing schedule step 7/84\n",
      "\tLayer: inception_3a_pool\n",
      "Processing schedule step 8/84\n",
      "\tLayer: inception_3a_1x1/Conv2D\n",
      "Processing schedule step 9/84\n",
      "\tLayer: inception_3a_3x3_reduce/Conv2D\n",
      "Processing schedule step 10/84\n",
      "\tLayer: inception_3a_3x3/Conv2D\n",
      "Processing schedule step 11/84\n",
      "\tLayer: inception_3a_5x5_reduce/Conv2D\n",
      "Processing schedule step 12/84\n",
      "\tLayer: inception_3a_5x5/Conv2D\n",
      "Processing schedule step 13/84\n",
      "\tLayer: inception_3a_pool_proj/Conv2D\n",
      "Processing schedule step 14/84\n",
      "\tLayer: inception_3a_output\n",
      "Processing schedule step 15/84\n",
      "\tLayer: inception_3b_pool\n",
      "Processing schedule step 16/84\n",
      "\tLayer: inception_3b_1x1/Conv2D\n",
      "Processing schedule step 17/84\n",
      "\tLayer: inception_3b_3x3_reduce/Conv2D\n",
      "Processing schedule step 18/84\n",
      "\tLayer: inception_3b_3x3/Conv2D\n",
      "Processing schedule step 19/84\n",
      "\tLayer: inception_3b_5x5_reduce/Conv2D\n",
      "Processing schedule step 20/84\n",
      "\tLayer: inception_3b_5x5/Conv2D\n",
      "Processing schedule step 21/84\n",
      "\tLayer: inception_3b_pool_proj/Conv2D\n",
      "Processing schedule step 22/84\n",
      "\tLayer: inception_3b_output\n",
      "Processing schedule step 23/84\n",
      "\tLayer: pool3_3x3_s2\n",
      "Processing schedule step 24/84\n",
      "\tLayer: inception_4a_pool\n",
      "Processing schedule step 25/84\n",
      "\tLayer: inception_4a_1x1/Conv2D\n",
      "Processing schedule step 26/84\n",
      "\tLayer: inception_4a_3x3_reduce/Conv2D\n",
      "Processing schedule step 27/84\n",
      "\tLayer: inception_4a_3x3/Conv2D\n",
      "Processing schedule step 28/84\n",
      "\tLayer: inception_4a_5x5_reduce/Conv2D\n",
      "Processing schedule step 29/84\n",
      "\tLayer: inception_4a_5x5/Conv2D\n",
      "Processing schedule step 30/84\n",
      "\tLayer: inception_4a_pool_proj/Conv2D\n",
      "Processing schedule step 31/84\n",
      "\tLayer: inception_4a_output\n",
      "Processing schedule step 32/84\n",
      "\tLayer: inception_4b_pool\n",
      "Processing schedule step 33/84\n",
      "\tLayer: inception_4b_1x1/Conv2D\n",
      "Processing schedule step 34/84\n",
      "\tLayer: inception_4b_3x3_reduce/Conv2D\n",
      "Processing schedule step 35/84\n",
      "\tLayer: inception_4b_3x3/Conv2D\n",
      "Processing schedule step 36/84\n",
      "\tLayer: inception_4b_5x5_reduce/Conv2D\n",
      "Processing schedule step 37/84\n",
      "\tLayer: inception_4b_5x5/Conv2D\n",
      "Processing schedule step 38/84\n",
      "\tLayer: inception_4b_pool_proj/Conv2D\n",
      "Processing schedule step 39/84\n",
      "\tLayer: inception_4b_output\n",
      "Processing schedule step 40/84\n",
      "\tLayer: inception_4c_pool\n",
      "Processing schedule step 41/84\n",
      "\tLayer: inception_4c_1x1/Conv2D\n",
      "Processing schedule step 42/84\n",
      "\tLayer: inception_4c_3x3_reduce/Conv2D\n",
      "Processing schedule step 43/84\n",
      "\tLayer: inception_4c_3x3/Conv2D\n",
      "Processing schedule step 44/84\n",
      "\tLayer: inception_4c_5x5_reduce/Conv2D\n",
      "Processing schedule step 45/84\n",
      "\tLayer: inception_4c_5x5/Conv2D\n",
      "Processing schedule step 46/84\n",
      "\tLayer: inception_4c_pool_proj/Conv2D\n",
      "Processing schedule step 47/84\n",
      "\tLayer: inception_4c_output\n",
      "Processing schedule step 48/84\n",
      "\tLayer: inception_4d_pool\n",
      "Processing schedule step 49/84\n",
      "\tLayer: inception_4d_1x1/Conv2D\n",
      "Processing schedule step 50/84\n",
      "\tLayer: inception_4d_3x3_reduce/Conv2D\n",
      "Processing schedule step 51/84\n",
      "\tLayer: inception_4d_3x3/Conv2D\n",
      "Processing schedule step 52/84\n",
      "\tLayer: inception_4d_5x5_reduce/Conv2D\n",
      "Processing schedule step 53/84\n",
      "\tLayer: inception_4d_5x5/Conv2D\n",
      "Processing schedule step 54/84\n",
      "\tLayer: inception_4d_pool_proj/Conv2D\n",
      "Processing schedule step 55/84\n",
      "\tLayer: inception_4d_output\n",
      "Processing schedule step 56/84\n",
      "\tLayer: inception_4e_pool\n",
      "Processing schedule step 57/84\n",
      "\tLayer: inception_4e_1x1/Conv2D\n",
      "Processing schedule step 58/84\n",
      "\tLayer: inception_4e_3x3_reduce/Conv2D\n",
      "Processing schedule step 59/84\n",
      "\tLayer: inception_4e_3x3/Conv2D\n",
      "Processing schedule step 60/84\n",
      "\tLayer: inception_4e_5x5_reduce/Conv2D\n",
      "Processing schedule step 61/84\n",
      "\tLayer: inception_4e_5x5/Conv2D\n",
      "Processing schedule step 62/84\n",
      "\tLayer: inception_4e_pool_proj/Conv2D\n",
      "Processing schedule step 63/84\n",
      "\tLayer: inception_4e_output\n",
      "Processing schedule step 64/84\n",
      "\tLayer: pool4_3x3_s2\n",
      "Processing schedule step 65/84\n",
      "\tLayer: inception_5a_pool\n",
      "Processing schedule step 66/84\n",
      "\tLayer: inception_5a_1x1/Conv2D\n",
      "Processing schedule step 67/84\n",
      "\tLayer: inception_5a_3x3_reduce/Conv2D\n",
      "Processing schedule step 68/84\n",
      "\tLayer: inception_5a_3x3/Conv2D\n",
      "Processing schedule step 69/84\n",
      "\tLayer: inception_5a_5x5_reduce/Conv2D\n",
      "Processing schedule step 70/84\n",
      "\tLayer: inception_5a_5x5/Conv2D\n",
      "Processing schedule step 71/84\n",
      "\tLayer: inception_5a_pool_proj/Conv2D\n",
      "Processing schedule step 72/84\n",
      "\tLayer: inception_5a_output\n",
      "Processing schedule step 73/84\n",
      "\tLayer: inception_5b_pool\n",
      "Processing schedule step 74/84\n",
      "\tLayer: inception_5b_1x1/Conv2D\n",
      "Processing schedule step 75/84\n",
      "\tLayer: inception_5b_3x3_reduce/Conv2D\n",
      "Processing schedule step 76/84\n",
      "\tLayer: inception_5b_3x3/Conv2D\n",
      "Processing schedule step 77/84\n",
      "\tLayer: inception_5b_5x5_reduce/Conv2D\n",
      "Processing schedule step 78/84\n",
      "\tLayer: inception_5b_5x5/Conv2D\n",
      "Processing schedule step 79/84\n",
      "\tLayer: inception_5b_pool_proj/Conv2D\n",
      "Processing schedule step 80/84\n",
      "\tLayer: inception_5b_output\n",
      "Processing schedule step 81/84\n",
      "\tLayer: pool5_7x7_s1\n",
      "Processing schedule step 82/84\n",
      "\tLayer: loss3_classifier/Reshape\n",
      "Processing schedule step 83/84\n",
      "\tLayer: loss3_classifier/loss3_classifier/MatMul\n",
      "Processing schedule step 84/84\n",
      "\tLayer: prob\n",
      "Done writing weights.\n",
      "SUCCESS\n",
      "SUCCESS\n",
      "Compiler successfully generated JSON and the data directory: work/bvlc_googlenet_without_lrn_test.pb_data\n",
      "**********\n",
      "Compilation Successful!\n",
      "\n",
      "Network Operations Count: 3286771040\n",
      "DDR Transfers (bytes): 0\n",
      "['../xfdnn/tools/quantize/calibration_directory/13923040300_b4c8521b4d_z.jpg', '../xfdnn/tools/quantize/calibration_directory/14931486720_37bd588ce9_z.jpg', '../xfdnn/tools/quantize/calibration_directory/15439525724_97d7cc2c81_z.jpg', '../xfdnn/tools/quantize/calibration_directory/16247716843_b419e8b111_z.jpg', '../xfdnn/tools/quantize/calibration_directory/3272651417_27976a64b3_z.jpg', '../xfdnn/tools/quantize/calibration_directory/3591612840_33710806df_z.jpg', '../xfdnn/tools/quantize/calibration_directory/36085792773_b9a3d115a3_z.jpg', '../xfdnn/tools/quantize/calibration_directory/4788821373_441cd29c9f_z.jpg', '../xfdnn/tools/quantize/calibration_directory/4814953542_de4b973dc2_z.jpg', '../xfdnn/tools/quantize/calibration_directory/5904386289_924b24d75d_z.jpg', '../xfdnn/tools/quantize/calibration_directory/7291910830_86a8ebb15d_z.jpg', '../xfdnn/tools/quantize/calibration_directory/7647574936_ffebfa2bea_z.jpg', '../xfdnn/tools/quantize/calibration_directory/78947826_fc79a94bf2_z.jpg', '../xfdnn/tools/quantize/calibration_directory/8289365270_82b20ef781_z.jpg', '../xfdnn/tools/quantize/calibration_directory/AdrianStoica_Rory_discdog.jpg']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying\n",
      "('Min: ', 0, ', Max: ', 150.993)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1504)\n",
      "('Mean : th_layer_out: ', 150.9929962158203, ', sf_layer_out: ', 0.00460808118582172)\n",
      "('Min: ', 0, ', Max: ', 1774.9265)\n",
      "('Min: ', 0, ', Max: ', 5280.0757)\n",
      "('Min: ', 0, ', Max: ', 1999.3662)\n",
      "('Min: ', 0, ', Max: ', 5696.549)\n",
      "('Min: ', 0, ', Max: ', 2007.4005)\n",
      "('n: ', 32768, ', len(bin_edges): ', 615)\n",
      "('Mean : th_layer_out: ', 5696.548828125, ', sf_layer_out: ', 0.1738501793916135)\n",
      "('Min: ', 0, ', Max: ', 2934.8054)\n",
      "('Min: ', 0, ', Max: ', 3054.7993)\n",
      "('Min: ', 0, ', Max: ', 2570.7114)\n",
      "('Min: ', 0, ', Max: ', 4279.9414)\n",
      "('n: ', 32768, ', len(bin_edges): ', 869)\n",
      "('Mean : th_layer_out: ', 2934.805419921875, ', sf_layer_out: ', 0.08956588701809366)\n",
      "('Min: ', 0, ', Max: ', 3253.8406)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1737)\n",
      "('Mean : th_layer_out: ', 1774.926513671875, ', sf_layer_out: ', 0.05416811162669378)\n",
      "('Min: ', 0, ', Max: ', 2232.0608)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 3054.79931640625, ', sf_layer_out: ', 0.09322792188501389)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1737)\n",
      "('Mean : th_layer_out: ', 1999.3662109375, ', sf_layer_out: ', 0.061017676654484695)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1064)\n",
      "('Mean : th_layer_out: ', 3253.840576171875, ', sf_layer_out: ', 0.09930236445728553)\n",
      "('Min: ', 0, ', Max: ', 2146.6743)\n",
      "('Min: ', 0, ', Max: ', 2595.6172)\n",
      "('Min: ', 0, ', Max: ', 2570.7114)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1737)\n",
      "('Mean : th_layer_out: ', 5280.07568359375, ', sf_layer_out: ', 0.16114003978373823)\n",
      "('Min: ', 0, ', Max: ', 1652.7562)\n",
      "('n: ', 32768, ', len(bin_edges): ', 435)\n",
      "('Mean : th_layer_out: ', 2146.67431640625, ', sf_layer_out: ', 0.06551330046712393)\n",
      "('n: ', 32768, ', len(bin_edges): ', 435)\n",
      "('Mean : th_layer_out: ', 1652.7562255859375, ', sf_layer_out: ', 0.050439656532057786)\n",
      "('Min: ', 0, ', Max: ', 2052.8293)\n",
      "('Min: ', 0, ', Max: ', 2570.7114)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1064)\n",
      "('Mean : th_layer_out: ', 2232.060791015625, ', sf_layer_out: ', 0.06811916840161214)\n",
      "('Min: ', 0, ', Max: ', 1935.5717)\n",
      "('n: ', 32768, ', len(bin_edges): ', 869)\n",
      " ('n: ', 32768, ', len(bin_edges): ', 615)\n",
      "('Mean : th_layer_out: ', 2052.829345703125, ', sf_layer_out: ', 0.06264929183944594)('Mean : th_layer_out: ', 2595.6171875, ', sf_layer_out: ', 0.07921436773277993)\n",
      "\n",
      "('n: ', 32768, ', len(bin_edges): ', 1504)\n",
      "('Mean : th_layer_out: ', 2570.71142578125, ', sf_layer_out: ', 0.07845428100775934)\n",
      "('Min: ', 0, ', Max: ', 2570.7114)\n",
      "('Min: ', 0, ', Max: ', 2239.405)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 1935.5716552734375, ', sf_layer_out: ', 0.05907076190293397)\n",
      "('Min: ', 0, ', Max: ', 1421.3508)\n",
      "('Min: ', 0, ', Max: ', 1743.1355)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1504)\n",
      "('Mean : th_layer_out: ', 2570.71142578125, ', sf_layer_out: ', 0.07845428100775934)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1504)\n",
      "('Mean : th_layer_out: ', 2570.71142578125, ', sf_layer_out: ', 0.07845428100775934)\n",
      "('Min: ', 0, ', Max: ', 1620.111)\n",
      "('Min: ', 0, ', Max: ', 1504.7615)\n",
      "('n: ', 32768, ', len(bin_edges): ', 615)\n",
      "('Mean : th_layer_out: ', 1620.1109619140625, ', sf_layer_out: ', 0.04944337174334124)\n",
      "('n: ', 32768, ', len(bin_edges): ', 435)\n",
      "('Mean : th_layer_out: ', 1504.761474609375, ', sf_layer_out: ', 0.04592307732198172)\n",
      "('Min: ', 0, ', Max: ', 1441.9553)\n",
      "('Min: ', 0, ', Max: ', 1179.1552)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1504)\n",
      "('Mean : th_layer_out: ', 2570.71142578125, ', sf_layer_out: ', 0.07845428100775934)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 1743.135498046875, ', sf_layer_out: ', 0.05319789721509064)\n",
      "('Min: ', 0, ', Max: ', 2239.405)\n",
      "('Min: ', 0, ', Max: ', 2239.405)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1737)\n",
      "('Mean : th_layer_out: ', 2239.405029296875, ', sf_layer_out: ', 0.06834330360719244)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1504)\n",
      "('Mean : th_layer_out: ', 1421.350830078125, ', sf_layer_out: ', 0.043377508776455735)\n",
      "('Min: ', 0, ', Max: ', 1360.6791)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1189)\n",
      "('Mean : th_layer_out: ', 1179.1551513671875, ', sf_layer_out: ', 0.035986057660670416)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 1441.955322265625, ', sf_layer_out: ', 0.04400632716652806)\n",
      "('Min: ', 0, ', Max: ', 2239.405)\n",
      "('Min: ', 0, ', Max: ', 2173.648)\n",
      "('Min: ', 0, ', Max: ', 1179.1552)\n",
      "('n: ', 32768, ', len(bin_edges): ', 615)\n",
      "('Mean : th_layer_out: ', 1360.6790771484375, ', sf_layer_out: ', 0.04152589730974571)\n",
      "('Min: ', 0, ', Max: ', 875.49164)\n",
      "('n: ', 32768, ', len(bin_edges): ', 753)\n",
      "('Mean : th_layer_out: ', 875.4916381835938, ', sf_layer_out: ', 0.02671869985606231)\n",
      "('Min: ', 0, ', Max: ', 1153.6328)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1064)\n",
      "('Mean : th_layer_out: ', 2173.64794921875, ', sf_layer_out: ', 0.06633649553571429)\n",
      "('Min: ', 0, ', Max: ', 671.8459)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1189)\n",
      "('Mean : th_layer_out: ', 1179.1551513671875, ', sf_layer_out: ', 0.035986057660670416)\n",
      "('n: ', 32768, ', len(bin_edges): ', 435)\n",
      "('Mean : th_layer_out: ', 671.8458862304688, ', sf_layer_out: ', 0.02050373504533429)\n",
      "('Min: ', 0, ', Max: ', 1179.1552)\n",
      "('Min: ', 0, ', Max: ', 1138.6232)\n",
      "('n: ', 32768, ', len(bin_edges): ', 783)\n",
      "('Mean : th_layer_out: ', 1153.6328125, ', sf_layer_out: ', 0.03520715392010254)\n",
      "('Min: ', 0, ', Max: ', 1138.5725)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1737)\n",
      "('Mean : th_layer_out: ', 2239.405029296875, ', sf_layer_out: ', 0.06834330360719244)\n",
      "('Min: ', 0, ', Max: ', 1138.4082)\n",
      "('n: ', 32768, ', len(bin_edges): ', 533)\n",
      "('Mean : th_layer_out: ', 1138.572509765625, ', sf_layer_out: ', 0.03474753592839213)\n",
      "('Min: ', 0, ', Max: ', 1179.1552)\n",
      "('n: ', 32768, ', len(bin_edges): ', 533)\n",
      "('Mean : th_layer_out: ', 1138.408203125, ', sf_layer_out: ', 0.03474252153462325)\n",
      "('Min: ', 0, ', Max: ', 802.7577)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1737)\n",
      "('Mean : th_layer_out: ', 2239.405029296875, ', sf_layer_out: ', 0.06834330360719244)\n",
      "('n: ', 32768, ', len(bin_edges): ', 218)\n",
      "('Mean : th_layer_out: ', 802.7576904296875, ', sf_layer_out: ', 0.02449896818230804)\n",
      "('Min: ', 0, ', Max: ', 802.1658)\n",
      "('Min: ', 0, ', Max: ', 872.5217)\n",
      "('n: ', 32768, ', len(bin_edges): ', 218)\n",
      "('Mean : th_layer_out: ', 802.165771484375, ', sf_layer_out: ', 0.0244809036983665)\n",
      "('n: ', 32768, ', len(bin_edges): ', 377)\n",
      "('Mean : th_layer_out: ', 872.521728515625, ', sf_layer_out: ', 0.02662806263971755)\n",
      "('Min: ', 0, ', Max: ', 473.0658)\n",
      "('Min: ', 0, ', Max: ', 379.53116)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 1138.6231689453125, ', sf_layer_out: ', 0.03474908197104747)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1189)\n",
      "('Mean : th_layer_out: ', 1179.1551513671875, ', sf_layer_out: ', 0.035986057660670416)\n",
      "('n: ', 32768, ', len(bin_edges): ', 687)\n",
      "('Mean : th_layer_out: ', 473.0657958984375, ', sf_layer_out: ', 0.01443726297489662)\n",
      "('Min: ', 0, ', Max: ', 522.0455)\n",
      "('Min: ', 0, ', Max: ', 1138.6232)\n",
      "('Min: ', 0, ', Max: ', 414.96222)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1737)\n",
      "('Mean : th_layer_out: ', 2239.405029296875, ', sf_layer_out: ', 0.06834330360719244)\n",
      "('Min: ', 0, ', Max: ', 587.89813)\n",
      "('n: ', 32768, ', len(bin_edges): ', 267)\n",
      "('Mean : th_layer_out: ', 522.0454711914062, ', sf_layer_out: ', 0.01593204965945635)\n",
      "('Min: ', 0, ', Max: ', 588.2274)\n",
      "('n: ', 32768, ', len(bin_edges): ', 435)\n",
      "('Mean : th_layer_out: ', 414.96221923828125, ', sf_layer_out: ', 0.01266402842000431)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1189)\n",
      "('Mean : th_layer_out: ', 1179.1551513671875, ', sf_layer_out: ', 0.035986057660670416)\n",
      "('n: ', 32768, ', len(bin_edges): ', 3007)\n",
      "('Mean : th_layer_out: ', 4279.94140625, ', sf_layer_out: ', 0.13061743236335338)\n",
      "('Min: ', 0, ', Max: ', 522.2376)\n",
      "('Min: ', 0, ', Max: ', 671.9917)\n",
      "('Min: ', 0, ', Max: ', 421.69226)\n",
      "('n: ', 32768, ', len(bin_edges): ', 575)\n",
      "('Mean : th_layer_out: ', 587.8981323242188, ', sf_layer_out: ', 0.01794177472225772)\n",
      "('n: ', 32768, ', len(bin_edges): ', 813)\n",
      "('Mean : th_layer_out: ', 379.5311584472656, ', sf_layer_out: ', 0.011582725255509067)\n",
      "('n: ', 32768, ', len(bin_edges): ', 435)\n",
      "('Mean : th_layer_out: ', 421.6922607421875, ', sf_layer_out: ', 0.012869419255415128)\n",
      "('Min: ', 0, ', Max: ', 1138.6232)\n",
      "('n: ', 32768, ', len(bin_edges): ', 267)\n",
      "('Mean : th_layer_out: ', 522.2376098632812, ', sf_layer_out: ', 0.015937913445334673)\n",
      "('Min: ', 0, ', Max: ', 429.16992)\n",
      "('Min: ', 0, ', Max: ', 371.14996)\n",
      "('Min: ', 0, ', Max: ', 239.31544)\n",
      "('n: ', 32768, ', len(bin_edges): ', 575)\n",
      "('Mean : th_layer_out: ', 588.2274169921875, ', sf_layer_out: ', 0.017951823999517426)\n",
      "('n: ', 32768, ', len(bin_edges): ', 615)\n",
      "('Mean : th_layer_out: ', 429.169921875, ', sf_layer_out: ', 0.013097626327555163)\n",
      "('Min: ', 0, ', Max: ', 1138.6232)\n",
      "('Min: ', 0, ', Max: ', 334.1903)\n",
      "('n: ', 32768, ', len(bin_edges): ', 615)\n",
      "('Mean : th_layer_out: ', 371.14996337890625, ', sf_layer_out: ', 0.011326943674395162)\n",
      "('Min: ', 0, ', Max: ', 352.19025)\n",
      "('n: ', 32768, ', len(bin_edges): ', 435)\n",
      "('Mean : th_layer_out: ', 334.1903076171875, ', sf_layer_out: ', 0.010198990069801553)\n",
      "('n: ', 32768, ', len(bin_edges): ', 267)\n",
      "('Mean : th_layer_out: ', 352.19024658203125, ', sf_layer_out: ', 0.010748321377667508)\n",
      "('Min: ', 0, ', Max: ', 429.36246)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 1138.6231689453125, ', sf_layer_out: ', 0.03474908197104747)\n",
      "('n: ', 32768, ', len(bin_edges): ', 869)\n",
      " ('Min: ', 0, ', Max: ', 671.9917)\n",
      "('Mean : th_layer_out: ', 239.31544494628906, ', sf_layer_out: ', 0.007303550674345807)\n",
      "('Min: ', 0, ', Max: ', 371.49768)\n",
      "('Min: ', 0, ', Max: ', 671.9917)\n",
      "('n: ', 32768, ', len(bin_edges): ', 3472)\n",
      "('Mean : th_layer_out: ', 2007.4005126953125, ', sf_layer_out: ', 0.061262871568813514)\n",
      "('Min: ', 0, ', Max: ', 350.77136)\n",
      "('n: ', 32768, ', len(bin_edges): ', 267)\n",
      "('Mean : th_layer_out: ', 350.7713623046875, ', sf_layer_out: ', 0.010705019144404049)\n",
      "('Min: ', 0, ', Max: ', 417.4522)\n",
      "('n: ', 32768, ', len(bin_edges): ', 615)\n",
      "('Mean : th_layer_out: ', 371.4976806640625, ', sf_layer_out: ', 0.01133755548765717)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 671.99169921875, ', sf_layer_out: ', 0.020508185040398877)\n",
      "('n: ', 32768, ', len(bin_edges): ', 435)\n",
      "('Mean : th_layer_out: ', 417.45220947265625, ', sf_layer_out: ', 0.012740019210567225)\n",
      "('Min: ', 0, ', Max: ', 671.9917)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 1138.6231689453125, ', sf_layer_out: ', 0.03474908197104747)\n",
      "('Min: ', 0, ', Max: ', 281.02316)\n",
      "('n: ', 32768, ', len(bin_edges): ', 575)\n",
      "('Mean : th_layer_out: ', 281.0231628417969, ', sf_layer_out: ', 0.00857640805816208)\n",
      "('Min: ', 0, ', Max: ', 298.60782)\n",
      "('Min: ', 0, ', Max: ', 298.23724)\n",
      "('Min: ', 0, ', Max: ', 299.69852)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 1138.6231689453125, ', sf_layer_out: ', 0.03474908197104747)\n",
      "('n: ', 32768, ', len(bin_edges): ', 652)\n",
      "('Mean : th_layer_out: ', 298.6078186035156, ', sf_layer_out: ', 0.009113065541658243)\n",
      "('n: ', 32768, ', len(bin_edges): ', 652)\n",
      "('Mean : th_layer_out: ', 298.23724365234375, ', sf_layer_out: ', 0.009101756146499336)\n",
      "('Min: ', 0, ', Max: ', 348.25443)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 429.3624572753906, ', sf_layer_out: ', 0.013103502220996448)\n",
      "('Min: ', 0, ', Max: ', 98.86968)\n",
      "('n: ', 32768, ', len(bin_edges): ', 308)\n",
      "('Mean : th_layer_out: ', 348.2544250488281, ', sf_layer_out: ', 0.010628205970910616)\n",
      "('Min: ', 0, ', Max: ', 429.36246)\n",
      "('Min: ', 0, ', Max: ', 429.36246)\n",
      "('Min: ', 0, ', Max: ', 429.36246)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 671.99169921875, ', sf_layer_out: ', 0.020508185040398877)\n",
      "('Min: ', 0, ', Max: ', 348.26794)\n",
      "('n: ', 32768, ', len(bin_edges): ', 922)\n",
      "('n: ', 32768, ', len(bin_edges): ', 308)\n",
      "('Mean : th_layer_out: ', 348.2679443359375, ', sf_layer_out: ', 0.010628618559402371)('Mean : th_layer_out: ', 299.6985168457031, ', sf_layer_out: ', 0.009146352026297894)\n",
      "\n",
      "('Min: ', 0, ', Max: ', 334.23688)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 671.99169921875, ', sf_layer_out: ', 0.020508185040398877)\n",
      "('Min: ', 0, ', Max: ', 154.0716)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 671.99169921875, ', sf_layer_out: ', 0.020508185040398877)\n",
      "('n: ', 32768, ', len(bin_edges): ', 435)\n",
      "('Mean : th_layer_out: ', 334.23687744140625, ', sf_layer_out: ', 0.010200411311423269)\n",
      "('Min: ', 0, ', Max: ', 334.55753)\n",
      "('Min: ', 0, ', Max: ', 334.55753)\n",
      "('Min: ', 0, ', Max: ', 334.55753)\n",
      "('n: ', 32768, ', len(bin_edges): ', 971)\n",
      "('Mean : th_layer_out: ', 98.86968231201172, ', sf_layer_out: ', 0.0030173553365279615)\n",
      "('n: ', 32768, ', len(bin_edges): ', 615)\n",
      "('Mean : th_layer_out: ', 154.07159423828125, ', sf_layer_out: ', 0.004702035408742981)\n",
      "('Min: ', 0, ', Max: ', 220.05045)\n",
      "('Min: ', 0, ', Max: ', 112.8721)\n",
      "('n: ', 32768, ', len(bin_edges): ', 308)\n",
      "('Mean : th_layer_out: ', 220.05044555664062, ', sf_layer_out: ', 0.006715611607917741)\n",
      "('Min: ', 0, ', Max: ', 218.80461)\n",
      "('n: ', 32768, ', len(bin_edges): ', 308)\n",
      "('Mean : th_layer_out: ', 218.8046112060547, ', sf_layer_out: ', 0.006677590600483861)\n",
      "('Min: ', 0, ', Max: ', 193.0661)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 429.3624572753906, ', sf_layer_out: ', 0.013103502220996448)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 429.3624572753906, ', sf_layer_out: ', 0.013103502220996448)\n",
      "('n: ', 32768, ', len(bin_edges): ', 687)\n",
      "('Mean : th_layer_out: ', 112.87210083007812, ', sf_layer_out: ', 0.00344468827875845)\n",
      "('Min: ', 0, ', Max: ', 112.39923)\n",
      "('Min: ', 0, ', Max: ', 146.46413)\n",
      "('Min: ', 0, ', Max: ', 334.55753)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 429.3624572753906, ', sf_layer_out: ', 0.013103502220996448)\n",
      "('n: ', 32768, ', len(bin_edges): ', 308)\n",
      "('Mean : th_layer_out: ', 146.46412658691406, ', sf_layer_out: ', 0.004469866835136389)\n",
      "('Min: ', 0, ', Max: ', 174.40556)\n",
      "('n: ', 32768, ', len(bin_edges): ', 615)\n",
      "('Mean : th_layer_out: ', 193.06610107421875, ', sf_layer_out: ', 0.005892089635127377)('Min: ', 0, ', Max: ', 174.51373)\n",
      "\n",
      "('Min: ', 0, ', Max: ', 103.46168)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1247)\n",
      "('Mean : th_layer_out: ', 334.5575256347656, ', sf_layer_out: ', 0.010210197016350769)\n",
      "('n: ', 32768, ', len(bin_edges): ', 435)\n",
      "('Mean : th_layer_out: ', 103.46167755126953, ', sf_layer_out: ', 0.003157496186750985)\n",
      "('Min: ', 0, ', Max: ', 108.16423)\n",
      "('Min: ', 0, ', Max: ', 108.61749)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1247)\n",
      "('Mean : th_layer_out: ', 334.5575256347656, ', sf_layer_out: ', 0.010210197016350769)\n",
      "('n: ', 32768, ', len(bin_edges): ', 687)\n",
      "('Mean : th_layer_out: ', 112.39923095703125, ', sf_layer_out: ', 0.0034302569950569553)\n",
      " ('Min: ', 0, ', Max: ', 108.578415)\n",
      "('n: ', 32768, ', len(bin_edges): ', 344)\n",
      "('Mean : th_layer_out: ', 108.61749267578125, ', sf_layer_out: ', 0.0033148439794848856)\n",
      "('Min: ', 0, ', Max: ', 138.17111)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1247)\n",
      "('Mean : th_layer_out: ', 334.5575256347656, ', sf_layer_out: ', 0.010210197016350769)\n",
      "('Min: ', 0, ', Max: ', 101.8357)\n",
      "('n: ', 32768, ', len(bin_edges): ', 783)\n",
      "('Mean : th_layer_out: ', 174.51373291015625, ', sf_layer_out: ', 0.005325899011510247)\n",
      "('n: ', 32768, ', len(bin_edges): ', 155)\n",
      " ('Min: ', 0, ', Max: ', 174.51373)\n",
      "('Mean : th_layer_out: ', 138.17111206054688, ', sf_layer_out: ', 0.00421677639272887)\n",
      "('n: ', 32768, ', len(bin_edges): ', 486)('n: ', 32768, ', len(bin_edges): ', 344)\n",
      "\n",
      "('Mean : th_layer_out: ', 108.16423034667969, ', sf_layer_out: ', 0.003301011088799087)\n",
      "('Mean : th_layer_out: ', 108.57841491699219, ', sf_layer_out: ', 0.003313651384532981)\n",
      "('Min: ', 0, ', Max: ', 174.51373)\n",
      "('Min: ', 0, ', Max: ', 174.51373) ('Min: ', 0, ', Max: ', 136.51385)\n",
      "\n",
      "('Min: ', 0, ', Max: ', 186.14029)\n",
      "('n: ', 32768, ', len(bin_edges): ', 308)\n",
      "('Mean : th_layer_out: ', 101.83570098876953, ', sf_layer_out: ', 0.0031078738056205795)\n",
      "('n: ', 32768, ', len(bin_edges): ', 155)('Min: ', 0, ', Max: ', 185.91138)\n",
      "\n",
      "('Mean : th_layer_out: ', 136.51385498046875, ', sf_layer_out: ', 0.0041661993768263425)\n",
      "('n: ', 32768, ', len(bin_edges): ', 869)\n",
      "('Mean : th_layer_out: ', 174.4055633544922, ', sf_layer_out: ', 0.005322597837900699)\n",
      "('n: ', 32768, ', len(bin_edges): ', 308)\n",
      "('Mean : th_layer_out: ', 186.14028930664062, ', sf_layer_out: ', 0.005680724183069571)\n",
      "('Min: ', 0, ', Max: ', 68.63063)\n",
      "('n: ', 32768, ', len(bin_edges): ', 783)\n",
      "('Mean : th_layer_out: ', 174.51373291015625, ', sf_layer_out: ', 0.005325899011510247)\n",
      "('Min: ', 0, ', Max: ', 62.387283)('Min: ', 0, ', Max: ', 185.91138)\n",
      "\n",
      "('Min: ', 0, ', Max: ', 69.11551)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1247)\n",
      "('Mean : th_layer_out: ', 334.5575256347656, ', sf_layer_out: ', 0.010210197016350769)\n",
      "('n: ', 32768, ', len(bin_edges): ', 308)\n",
      "('Mean : th_layer_out: ', 68.63063049316406, ', sf_layer_out: ', 0.002094504547049289)\n",
      "('Min: ', 0, ', Max: ', 98.58113)\n",
      " ('Min: ', 0, ', Max: ', 74.48598)\n",
      "('n: ', 32768, ', len(bin_edges): ', 783)\n",
      "('Mean : th_layer_out: ', 174.51373291015625, ', sf_layer_out: ', 0.005325899011510247)\n",
      "('Min: ', 0, ', Max: ', 76.995605)\n",
      "('n: ', 32768, ', len(bin_edges): ', 783) \n",
      "('Mean : th_layer_out: ', 174.51373291015625, ', sf_layer_out: ', 0.005325899011510247)\n",
      "('n: ', 32768, ', len(bin_edges): ', 189)\n",
      "('Mean : th_layer_out: ', 74.48597717285156, ', sf_layer_out: ', 0.002273201000178581)\n",
      "('n: ', 32768, ', len(bin_edges): ', 189)\n",
      " ('Min: ', 0, ', Max: ', 98.51231)('Mean : th_layer_out: ', 76.99560546875, ', sf_layer_out: ', 0.002349791115108188)\n",
      "\n",
      "('Min: ', 0, ', Max: ', 185.91138)\n",
      "('Min: ', 0, ', Max: ', 185.91138)\n",
      " ('n: ', 32768, ', len(bin_edges): ', 377)\n",
      "('Mean : th_layer_out: ', 98.58113098144531, ', sf_layer_out: ', 0.003008549180011759)('n: ', 32768, ', len(bin_edges): ', 533)\n",
      "\n",
      "('Mean : th_layer_out: ', 69.11550903320312, ', sf_layer_out: ', 0.002109302317368179)\n",
      "('n: ', 32768, ', len(bin_edges): ', 533)\n",
      "('Mean : th_layer_out: ', 62.38728332519531, ', sf_layer_out: ', 0.0019039668973416949)\n",
      "('n: ', 32768, ', len(bin_edges): ', 377)\n",
      "('Mean : th_layer_out: ', 98.5123062133789, ', sf_layer_out: ', 0.0030064487506753414)\n",
      "('n: ', 32768, ', len(bin_edges): ', 783)\n",
      "('Mean : th_layer_out: ', 185.911376953125, ', sf_layer_out: ', 0.005673738119239631)\n",
      "('n: ', 32768, ', len(bin_edges): ', 783)\n",
      "('Mean : th_layer_out: ', 185.911376953125, ', sf_layer_out: ', 0.005673738119239631)\n",
      "('n: ', 32768, ', len(bin_edges): ', 783)\n",
      "('Mean : th_layer_out: ', 185.911376953125, ', sf_layer_out: ', 0.005673738119239631)\n",
      "('n: ', 32768, ', len(bin_edges): ', 783)\n",
      "('Mean : th_layer_out: ', 185.911376953125, ', sf_layer_out: ', 0.005673738119239631)\n",
      "('Min: ', 0, ', Max: ', 185.91138)\n",
      "('Min: ', 0, ', Max: ', 48.916332)\n",
      "('Min: ', 0, ', Max: ', 1138.6232)('Min: ', 0, ', Max: ', 429.36246)\n",
      "\n",
      "('Min: ', 0, ', Max: ', 174.51373)\n",
      " ('Min: ', 0, ', Max: ', 671.9917)\n",
      "('Min: ', 0, ', Max: ', 334.55753)\n",
      "('Min: ', 0, ', Max: ', 1179.1552)\n",
      "('n: ', 32768, ', len(bin_edges): ', 783)\n",
      "('Mean : th_layer_out: ', 185.911376953125, ', sf_layer_out: ', 0.005673738119239631)\n",
      "('n: ', 32768, ', len(bin_edges): ', 869)\n",
      "('Mean : th_layer_out: ', 48.91633224487305, ', sf_layer_out: ', 0.001492853549146185)\n",
      "('Min: ', 0, ', Max: ', 2239.405)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 671.99169921875, ', sf_layer_out: ', 0.020508185040398877)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1247)\n",
      "('Mean : th_layer_out: ', 334.5575256347656, ', sf_layer_out: ', 0.010210197016350769)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 429.3624572753906, ', sf_layer_out: ', 0.013103502220996448)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1228)\n",
      "('Mean : th_layer_out: ', 1138.6231689453125, ', sf_layer_out: ', 0.03474908197104747)\n",
      "('n: ', 32768, ', len(bin_edges): ', 1565)\n",
      "('Mean : th_layer_out: ', 174.51373291015625, ', sf_layer_out: ', 0.005325899011510247)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('n: ', 32768, ', len(bin_edges): ', 1737)\n",
      "('Mean : th_layer_out: ', 2239.405029296875, ', sf_layer_out: ', 0.06834330360719244)\n",
      "('n: ', 32768, ', len(bin_edges): ', 2377)\n",
      "('Mean : th_layer_out: ', 1179.1551513671875, ', sf_layer_out: ', 0.035986057660670416)\n",
      "Writing output files to work/quantization_params.json...\n",
      "**********\n",
      "Successfully produced quantization JSON file for 57 layers.\n",
      "\n",
      "INFO: Successfully created handle to FPGA\n",
      "starting prediction for batchsize : 1 over 1 images\n",
      "Loading weights/bias/quant_params to FPGA...\n",
      "starting prediction for batchsize : 2 over 2 images\n",
      "Loading weights/bias/quant_params to FPGA...\n",
      "starting prediction for batchsize : 4 over 4 images\n",
      "Loading weights/bias/quant_params to FPGA...\n",
      "starting prediction for batchsize : 8 over 8 images\n",
      "Loading weights/bias/quant_params to FPGA...\n",
      "starting prediction for batchsize : 16 over 16 images\n",
      "Loading weights/bias/quant_params to FPGA...\n",
      "starting prediction for batchsize : 32 over 32 images\n",
      "Loading weights/bias/quant_params to FPGA...\n",
      "starting prediction for batchsize : 64 over 64 images\n",
      "Loading weights/bias/quant_params to FPGA...\n"
     ]
    }
   ],
   "source": [
    "#Provide the Model checkpoint path\n",
    "\n",
    "sProtoBufPath=\"/home/centos/models/tensorflow/bvlc_googlenet_without_lrn/fp32/bvlc_googlenet_without_lrn_test.pb\"\n",
    "\n",
    "#Intantiate the FPGA configuration\n",
    "config,handle=initializeFpgaModel(sProtoBufPath)\n",
    "\n",
    "Inference_Data =[]\n",
    "#Get Image batch to start inference\n",
    "for i in range(0,7):\n",
    "    \n",
    "    iBatchSize = 2**i\n",
    "    \n",
    "    #Generate batch 10 * batchsize\n",
    "    batch_array=generateRandomBatch(1*iBatchSize,config)\n",
    "    \n",
    "    print(\"starting prediction for batchsize : {} over {} images\".format(iBatchSize,len(batch_array)))\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #Run prdeiction on FPGA\n",
    "    out,actualTime = runOnFPGA(iBatchSize,config,handle,batch_array)\n",
    "   \n",
    "    end = time.time()\n",
    "    \n",
    "    duration = end-start\n",
    "    \n",
    "    Inference_Data.append({\"duration\":duration, \"duration_actual_run\":actualTime\n",
    "                                         ,\"imgsPerSec\": len(batch_array)/duration,\"batchSize\":iBatchSize,\n",
    "                                          \"imgsPerSecAc\": len(batch_array)/actualTime})\n",
    "    del batch_array,out\n",
    "    gc.collect()\n",
    "\n",
    "    #Close the fpga handle \n",
    "xdnn.closeHandle()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batchSize</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_actual_run</th>\n",
       "      <th>imgsPerSec</th>\n",
       "      <th>imgsPerSecAc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.907825</td>\n",
       "      <td>0.007808</td>\n",
       "      <td>0.343900</td>\n",
       "      <td>128.074262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.764549</td>\n",
       "      <td>0.009607</td>\n",
       "      <td>0.723445</td>\n",
       "      <td>208.185040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2.779084</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>1.439323</td>\n",
       "      <td>234.646378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2.796970</td>\n",
       "      <td>0.031426</td>\n",
       "      <td>2.860238</td>\n",
       "      <td>254.566664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>2.843636</td>\n",
       "      <td>0.060329</td>\n",
       "      <td>5.626600</td>\n",
       "      <td>265.212593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>2.911557</td>\n",
       "      <td>0.118503</td>\n",
       "      <td>10.990683</td>\n",
       "      <td>270.035144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>3.035080</td>\n",
       "      <td>0.234035</td>\n",
       "      <td>21.086759</td>\n",
       "      <td>273.463353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batchSize  duration  duration_actual_run  imgsPerSec  imgsPerSecAc\n",
       "0          1  2.907825             0.007808    0.343900    128.074262\n",
       "1          2  2.764549             0.009607    0.723445    208.185040\n",
       "2          4  2.779084             0.017047    1.439323    234.646378\n",
       "3          8  2.796970             0.031426    2.860238    254.566664\n",
       "4         16  2.843636             0.060329    5.626600    265.212593\n",
       "5         32  2.911557             0.118503   10.990683    270.035144\n",
       "6         64  3.035080             0.234035   21.086759    273.463353"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print inference data and plot\n",
    "Inference_Data = pd.DataFrame(Inference_Data)\n",
    "Inference_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2529282f50>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.path as mpath\n",
    "f, ax = plt.subplots(figsize=(15, 10))\n",
    "plt.title('Number of connections to port')\n",
    "ax.set_xlabel(\"Batch Size\")\n",
    "plt.ylabel('Images Processed per second')\n",
    "plt.xticks(Inference_Data['batchSize'], Inference_Data['batchSize'])\n",
    "#plot images processed without initializing host memory ports- done on changing batch size\n",
    "ax.plot(Inference_Data['batchSize'],Inference_Data['imgsPerSecAc'],marker='x', markersize=10)\n",
    "#plot images processed with initializing host memory ports\n",
    "ax.plot(Inference_Data['batchSize'],Inference_Data['imgsPerSec'],marker='x', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
