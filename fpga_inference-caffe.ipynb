{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/centos/ml-suite/notebooks/pickle', '/home/centos/ml-suite/notebooks/parallel', '/home/centos/ml-suite/notebooks/bin', '/home/centos/ml-suite/notebooks/version', '/home/centos/ml-suite/notebooks/weights', '/home/centos/ml-suite/notebooks/optimizations', '/home/centos/ml-suite/notebooks/network', '/home/centos/ml-suite/notebooks/memory', '/home/centos/ml-suite/notebooks/graph', '/home/centos/ml-suite/notebooks/codegeneration', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../weights', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../version', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../tests', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../pickle', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../parallel', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../optimizations', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../network', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../memory', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../graph', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../fpga_definition', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../examples', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../docs', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../codegeneration', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../client-resnet', '/home/centos/ml-suite/xfdnn/tools/compile/bin/../bin', '', '/home/centos/ml-suite', '/home/centos/ml-suite/xfdnn/rt', '/home/centos/ml-suite/ext', '/home/centos/ml-suite/models/darknet/tools', '/home/centos/ml-suite/apps/yolo', '/home/centos/ml-suite/apps/yolo/nms', '/home/centos/ml-suite/xfdnn/tools/emu', '/home/centos/ml-suite/xfdnn/tools/compile/network', '/home/centos/ml-suite/xfdnn/tools/compile/graph', '/home/centos/ml-suite/xfdnn/tools/compile/optimizations', '/home/centos/ml-suite/xfdnn/tools/compile/codegeneration', '/home/centos/ml-suite/xfdnn/tools/compile/memory', '/home/centos/ml-suite/xfdnn/tools/compile/version', '/home/centos/ml-suite/xfdnn/tools/compile/weights', '/home/centos/ml-suite/xfdnn/tools/compile/bin', '/home/centos/ml-suite/xfdnn/tools/compile/parallel', '/home/centos/ml-suite/xfmlp/python', '/home/centos/anaconda2/envs/ml-suite/lib/python27.zip', '/home/centos/anaconda2/envs/ml-suite/lib/python2.7', '/home/centos/anaconda2/envs/ml-suite/lib/python2.7/plat-linux2', '/home/centos/anaconda2/envs/ml-suite/lib/python2.7/lib-tk', '/home/centos/anaconda2/envs/ml-suite/lib/python2.7/lib-old', '/home/centos/anaconda2/envs/ml-suite/lib/python2.7/lib-dynload', '/home/centos/anaconda2/envs/ml-suite/lib/python2.7/site-packages', '/home/centos/anaconda2/envs/ml-suite/lib/python2.7/site-packages/pydot_ng-1.0.1.dev0-py2.7.egg', '/home/centos/anaconda2/envs/ml-suite/lib/python2.7/site-packages/IPython/extensions', '/home/centos/.ipython']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1a471c461caf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Bring in Xilinx ML Suite Compiler, Quantizer, PyXDNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#from xfdnn.tools.compile.bin.xfdnn_compiler_tensorflow import TFFrontend as xfdnnCompiler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxfdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxfdnn_compiler_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCaffeFrontend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxfdnnCompiler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxfdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCaffeFrontend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxfdnnQuantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#from xfdnn.tools.quantize.quantize_tf import tf_Quantizer as xfdnnQuantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m./xfdnn/tools/compile/bin/xfdnn_compiler_caffe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcaffe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "# Import some things\n",
    "import os,sys,cv2\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Bring in Xilinx ML Suite Compiler, Quantizer, PyXDNN\n",
    "#from xfdnn.tools.compile.bin.xfdnn_compiler_tensorflow import TFFrontend as xfdnnCompiler\n",
    "from xfdnn.tools.compile.bin.xfdnn_compiler_caffe import CaffeFrontend as xfdnnCompiler\n",
    "from xfdnn.tools.quantize.quantize import CaffeFrontend as xfdnnQuantizer\n",
    "#from xfdnn.tools.quantize.quantize_tf import tf_Quantizer as xfdnnQuantizer\n",
    "import xfdnn.rt.xdnn as xdnn\n",
    "import xfdnn.rt.xdnn_io as xdnn_io\n",
    "import time\n",
    "import ipywidgets\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "import pandas as pd\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "print(\"Current working directory: %s\" % os.getcwd())\n",
    "print(\"Running on host: %s\" % os.uname()[1])\n",
    "print(\"Running w/ LD_LIBRARY_PATH: %s\" %  os.environ[\"LD_LIBRARY_PATH\"])\n",
    "print(\"Running w/ XILINX_OPENCL: %s\" %  os.environ[\"XILINX_OPENCL\"])\n",
    "print(\"Running w/ XCLBIN_PATH: %s\" %  os.environ[\"XCLBIN_PATH\"])\n",
    "print(\"Running w/ PYTHONPATH: %s\" %  os.environ[\"PYTHONPATH\"])\n",
    "print(\"Running w/ SDACCEL_INI_PATH: %s\" %  os.environ[\"SDACCEL_INI_PATH\"])\n",
    "\n",
    "id = !whoami\n",
    "\n",
    "# Make sure there is no error in this cell\n",
    "# The xfDNN runtime depends upon the above environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeFpgaModel(sProtoBufPath):\n",
    "    config = {} # Config dict\n",
    "    config[\"platform\"] = 'aws'\n",
    "    \n",
    "    sInputNode,sOutputNode = getModelInputOutputNode(sProtoBufPath)\n",
    "    # Compiler Arguments\n",
    "    config[\"model\"] = \"GoogLeNet\"\n",
    "    #config[\"protobuf\"] = \"/home/centos/models/tensorflow/inception/frozen_inception_v3.pb\"\n",
    "    #config[\"protobuf\"] = sProtoBufPath\n",
    "    #config[\"outmodel\"] = \"work/optimized_model\" # String for naming optimized model NOT YET SUPPORTED\n",
    "    config[\"prototxt\"]     =\"/home/centos/models/caffe/inception_v3/fp32/inception_v3_deploy.prototxt\"\n",
    "    #config[\"caffemodel\"]   = \"../models/caffe/resnet/fp32/resnet50_without_bn.caffemodel\"\n",
    "    config[\"caffemodel\"]   =\"/home/centos/models/caffe/inception_v3/fp32/inception_v3.caffemodel\"\n",
    "    config[\"outmodel\"]     = \"work/opt_inception_model\"\n",
    "    \n",
    "    config[\"netcfg\"] = \"work/fpga_caffe.cmds\" # Compiler will generate FPGA instructions\n",
    "    config[\"memory\"] = 5 # Available on-chip SRAM\n",
    "    config[\"dsp\"] = 28 # Width of Systolic Array\n",
    "    #config[\"finalnode\"] = sOutputNode # Terminal node in your tensorflow graph\n",
    "    #config[\"finalnode\"] = \"prob\" # Terminal node in your tensorflow graph\n",
    "\n",
    "    compiler = xfdnnCompiler(\n",
    "        networkfile=config[\"prototxt\"],      # Protobuf filename: input file\n",
    "        anew=config[\"outmodel\"],            # String for intermediate protobuf NOT YET SUPPORTED\n",
    "        generatefile=config[\"netcfg\"],       # Script filename: output file\n",
    "        memory=config[\"memory\"],             # Available on chip SRAM within xclbin\n",
    "        dsp=config[\"dsp\"],                   # Rows in DSP systolic array within xclbin # keep defaults \n",
    "        #finalnode=config[\"finalnode\"],       # Terminal node in your tensorflow graph\n",
    "        weights=config[\"caffemodel\"]                         # Instruct Compiler to generate a weights directory for runtime\n",
    "    )\n",
    "\n",
    "# Invoke compiler\n",
    "    try:\n",
    "        compiler.compile()\n",
    "\n",
    "        # The compiler extracts the floating point weights from the .caffemodel.\n",
    "        # As it makes optimizations it will augment the weights, and generate a weights dir\n",
    "        # This weights dir will be stored in the work dir with the appendex '_data'. \n",
    "        # In the future, the compiler will generate a more efficient format such as hdf5\n",
    "        config[\"datadir\"] = \"work/\" + os.path.basename(config[\"caffemodel\"]) + \"_data\"    \n",
    "        if os.path.exists(config[\"datadir\"]) and os.path.exists(config[\"netcfg\"]+\".json\"):\n",
    "            print(\"Compiler successfully generated JSON and the data directory: %s\" % config[\"datadir\"])\n",
    "        else:\n",
    "            print(\"Compiler failed to generate the JSON or data directory: %s\" % config[\"datadir\"])\n",
    "            raise\n",
    "\n",
    "        print(\"**********\\nCompilation Successful!\\n\")\n",
    "\n",
    "        import json\n",
    "        data = json.loads(open(config[\"netcfg\"]+\".json\").read())\n",
    "        print(\"Network Operations Count: %d\"%data['ops'])\n",
    "        print(\"DDR Transfers (bytes): %d\"%data['moveops']) \n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Failed to complete compilation:\",e)\n",
    "\n",
    "    # Quantizing\n",
    "    config[\"img_mean\"] = [104.007, 116.669, 122.679] # Mean of the training set\n",
    "    config[\"output_json\"] = \"work/quantization_params_caffe.json\"\n",
    "    config[\"quantizecfg\"] =  config[\"output_json\"] # Quantizer will generate quantization params\n",
    "    config[\"calibration_directory\"] = \"../xfdnn/tools/quantize/calibration_directory\" # Directory of images for quantizer\n",
    "    config[\"calibration_size\"] = 15 # Number of calibration images quantizer will use\n",
    "    config[\"bitwidths\"] = [16,16,16] # Supported quantization precision\n",
    "    config[\"img_raw_scale\"] = 255.0 # Raw scale of input pixels, i.e. 0 <-> 255\n",
    "    config[\"img_input_scale\"] = 1.0 # Input multiplier, Images are scaled by this factor after mean subtraction\n",
    "    config[\"transpose\"] = [2,0,1] # (H,W,C)->(C,H,W) transpose argument to quantizer\n",
    "    config[\"channel_swap\"] = [2,1,0] # (R,G,B)->(B,G,R) Channel Swap argument to quantizer\n",
    "\n",
    "\n",
    "# Compiler instance\n",
    "    quantizer = xfdnnQuantizer(\n",
    "        deploy_model=config[\"outmodel\"]+\".prototxt\",          # Model filename: input file\n",
    "        weights=config[\"outmodel\"]+\".caffemodel\",             # Floating Point weights\n",
    "        output_json=config[\"output_json\"],                    # Quantization JSON output filename\n",
    "        bitwidths=config[\"bitwidths\"],                        # Fixed Point precision: 8,8,8 or 16,16,16\n",
    "        transpose=config[\"transpose\"],                        # Transpose argument to caffe transformer\n",
    "        channel_swap=config[\"channel_swap\"],                  # Channel swap argument to caffe transfomer\n",
    "        raw_scale=config[\"img_raw_scale\"],                    # Raw scale argument to caffe transformer\n",
    "        mean_value=config[\"img_mean\"],                        # Image mean per channel to caffe transformer\n",
    "        input_scale=config[\"img_input_scale\"],                # Input scale argument to caffe transformer\n",
    "        calibration_size=config[\"calibration_size\"],          # Number of calibration images to use\n",
    "        calibration_directory=config[\"calibration_directory\"] # Directory containing calbration images\n",
    "    )\n",
    "\n",
    "    # Invoke quantizer\n",
    "    try:\n",
    "        quantizer.quantize(inputName = sInputNode, outputName = sOutputNode)\n",
    "\n",
    "        import json\n",
    "        data = json.loads(open(config[\"quantizecfg\"]).read())\n",
    "        print(\"**********\\nSuccessfully produced quantization JSON file for %d layers.\\n\"%len(data['network']))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to quantize:\",e)\n",
    "\n",
    "    # Create a handle with which to communicate to the FPGA\n",
    "    # The actual handle is managed by xdnn\n",
    "    config[\"xclbin\"] = \"../overlaybins/\" + config[\"platform\"] + \"/overlay_3.xclbin\" # Chosen Hardware Overlay\n",
    "    ## NOTE: If you change the xclbin, we likely need to change some arguments provided to the compiler\n",
    "    ## Specifically, the DSP array width, and the memory arguments\n",
    "\n",
    "    ret, handles = xdnn.createHandle(config['xclbin'])\n",
    "\n",
    "    if ret:                                                             \n",
    "        print(\"ERROR: Unable to create handle to FPGA\")\n",
    "    else:\n",
    "        print(\"INFO: Successfully created handle to FPGA\")\n",
    "\n",
    "    # If this step fails, most likely the FPGA is locked by another user, or there is some setup problem with the hardware\n",
    "    return config,handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelInputOutputNode(sProtobufPath):\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.python.platform import gfile\n",
    "    with tf.Session() as sess:\n",
    "        with gfile.FastGFile(sProtobufPath,'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        sess.graph.as_default()\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "        graph_nodes=[n for n in graph_def.node]\n",
    "\n",
    "        return graph_nodes[0].name, graph_nodes[len(graph_nodes)-1].name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chose an image to run, display it for reference\n",
    "# config[\"images\"] = [\"../examples/classification/dog.jpg\",\"../examples/classification/dog.jpg\"] # Image of interest (Must provide as a list)\n",
    "\n",
    "# img = cv2.imread(config[\"images\"][0])\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(img)\n",
    "# plt.title(config[\"images\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize, and transfer the weights to FPGA DDR\n",
    "def TransferWeightsFPGA(iBatchSize,config,handles):\n",
    "    # config[\"datadir\"] = \"work/\" + config[\"caffemodel\"].split(\"/\")[-1]+\"_data\" # From Compiler\n",
    "    config[\"scaleA\"] = 10000 # Global scaler for weights (Must be defined)\n",
    "    config[\"scaleB\"] = 30 # Global scaler for bias (Must be defined)\n",
    "    config[\"PE\"] = 0 # Run on Processing Element 0 - Different xclbins have a different number of Elements\n",
    "    config[\"batch_sz\"] = iBatchSize # We will load 1 image at a time from disk\n",
    "    config[\"in_shape\"] = (3,224,224) # We will resize images to 224x224\n",
    "\n",
    "    #(weightsBlob, fcWeight, fcBias ) = pyxfdnn_io.loadWeights(config)\n",
    "    fpgaRT = xdnn.XDNNFPGAOp(handles,config)\n",
    "    (fcWeight, fcBias) = xdnn_io.loadFCWeightsBias(config)\n",
    "    return fpgaRT,fcWeight,fcBias,config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Allocate space in host memory for inputs, load images from disk, and prepare images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate space in host memory for inputs, Load images from disk\n",
    "def AllocateMemoryToHost(config):\n",
    "#     batch_array = np.empty(((config['batch_sz'],) + config['in_shape']), dtype=np.float32, order='C')\n",
    "#     img_paths = xdnn_io.getFilePaths(config['images'])\n",
    "\n",
    "#     for i in xrange(0, len(img_paths), config['batch_sz']):\n",
    "#         pl = []\n",
    "#         for j, p in enumerate(img_paths[i:i + config['batch_sz']]):\n",
    "#             batch_array[j, ...], _ = xdnn_io.loadImageBlobFromFile(p, config['img_raw_scale'], config['img_mean'], \n",
    "#                                                                       config['img_input_scale'], config['in_shape'][2], \n",
    "#                                                                       config['in_shape'][1])\n",
    "#             pl.append(p)\n",
    "    # Allocate space in host memory for outputs\n",
    "    if config[\"model\"] == \"GoogLeNet\":\n",
    "        config[\"fpgaoutsz\"] = 1024 # Number of elements in the activation of the last layer ran on the FPGA\n",
    "    elif config[\"model\"] == \"ResNet50\":\n",
    "        config[\"fpgaoutsz\"] = 2048 # Number of elements in the activation of the last layer ran on the FPGA\n",
    "\n",
    "    config[\"outsz\"] = 1000 # Number of elements output by FC layers (1000 used for imagenet)\n",
    "\n",
    "    fpgaOutput = np.empty ((config['batch_sz'], config['fpgaoutsz'],), dtype=np.float32, order='C') # Space for fpga output\n",
    "    fcOutput = np.empty((config['batch_sz'], config['outsz'],), dtype=np.float32, order='C') # Space for output of inner product\n",
    "   \n",
    "    return fpgaOutput, fcOutput,config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRandomBatch(iBatchSize,config):\n",
    "    return np.random.rand(iBatchSize,3,224,224).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12. Output the classification prediction scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the classification given the labels synset_words.txt (Imagenet classes)\n",
    "# config[\"labels\"] = \"../examples/classification/synset_words.txt\"\n",
    "# labels = xdnn_io.get_labels(config['labels'])\n",
    "# xdnn_io.printClassification(softmaxOut, pl, labels)\n",
    "\n",
    "# #Print Original Image for Reference \n",
    "# img = cv2.imread(config[\"images\"][0])\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(img)\n",
    "# plt.title(config[\"images\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runOnFPGA(iBatchSize,config,handle,batchArray):\n",
    "    # Load weights to FPGA\n",
    "    fpgaRT,fcWeight,fcBias,config=TransferWeightsFPGA(iBatchSize,config,handle)\n",
    "    \n",
    "    #Allocate Memory to host\n",
    "    fpgaOutput, fcOutput,config=AllocateMemoryToHost(config)\n",
    "    \n",
    "    #Generate Image batches to run\n",
    "#     batch_array= generateRandomBatch(iBatchSize,config)\n",
    "    \n",
    "    # Write FPGA Instructions to FPGA and Execute the network!\n",
    "    start = time.time()\n",
    "    fpgaRT.execute(batch_array, fpgaOutput)\n",
    "    \n",
    "    # Compute the inner product\n",
    "    xdnn.computeFC(fcWeight, fcBias, fpgaOutput, config['batch_sz'], config['outsz'], config['fpgaoutsz'], fcOutput)\n",
    "    \n",
    "    # Compute the softmax to convert the output to a vector of probabilities\n",
    "    softmaxOut = xdnn.computeSoftmax(fcOutput)\n",
    "    \n",
    "    #Return the output\n",
    "    return softmaxOut, time.time()-start    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(anew='work/opt_inception_model', approximate=False, banditpre=None, barrier=False, bridges=None, bytesperpixels=2, concatstrategy=None, conv_1x1_s2=False, cpulayermustgo=False, darius=None, ddr=256, dedicateddsp=None, deephifilename=None, dsp=28, forceweights=None, fromtensorflow=False, generatefile='work/fpga_caffe.cmds', godreplication=None, lasttensorbyname=None, loadpickle=None, manasadebugmode=False, memory=5, networkfile='/home/centos/models/caffe/inception_v3/fp32/inception_v3_deploy.prototxt', nodynamicscaling=False, noreplication=False, parallelism=False, parallelismstrategy=\"['bottom', 'tops']\", parallelread=None, phase='TEST', pipelineconvmaxpool=False, pngfile=None, poolingaround=False, rankdir='BT', savepickle=None, schedulefile=None, strategy='all', verbose=False, versionjson=None, weights='/home/centos/models/caffe/inception_v3/fp32/inception_v3.caffemodel')\n",
      "Network: /home/centos/models/caffe/inception_v3/fp32/inception_v3_deploy.prototxt\n",
      "GenerateCode: work/fpga_caffe.cmds\n",
      "Weights: /home/centos/models/caffe/inception_v3/fp32/inception_v3.caffemodel\n",
      "PngFile: None\n",
      "ConcatStrategy: None\n",
      "Strategy: all\n",
      "ScheduleFile: None\n",
      "DDR: 256\n",
      "DSP: 28\n",
      "DSP V2\n",
      "Verbose: False\n",
      "FromTF: False\n",
      "Memory: 5\n",
      "**************************************************\n",
      "* HARDWARE\n",
      "**************************************************\n",
      "Phase: TEST\n",
      "RankDir: BT\n",
      "\n",
      "**************************************************\n",
      "* BUILDING DATA FLOW GRAPH\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "#Provide the Model checkpoint path\n",
    "\n",
    "sProtoBufPath=\"/home/centos/models/tensorflow/bvlc_googlenet_without_lrn/fp32/bvlc_googlenet_without_lrn_test.pb\"\n",
    "\n",
    "#Intantiate the FPGA configuration\n",
    "config,handle=initializeFpgaModel(sProtoBufPath)\n",
    "\n",
    "Inference_Data =[]\n",
    "#Get Image batch to start inference\n",
    "for i in range(0,7):\n",
    "    \n",
    "    iBatchSize = 2**i\n",
    "    \n",
    "    #Generate batch 10 * batchsize\n",
    "    batch_array=generateRandomBatch(1*iBatchSize,config)\n",
    "    \n",
    "    print(\"starting prediction for batchsize : {} over {} images\".format(iBatchSize,len(batch_array)))\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #Run prdeiction on FPGA\n",
    "    out,actualTime = runOnFPGA(iBatchSize,config,handle,batch_array)\n",
    "   \n",
    "    end = time.time()\n",
    "    \n",
    "    duration = end-start\n",
    "    \n",
    "    Inference_Data.append({\"duration\":duration, \"duration_actual_run\":actualTime\n",
    "                                         ,\"imgsPerSec\": len(batch_array)/duration,\"batchSize\":iBatchSize,\n",
    "                                          \"imgsPerSecAc\": len(batch_array)/actualTime})\n",
    "    del batch_array,out\n",
    "    gc.collect()\n",
    "\n",
    "    #Close the fpga handle \n",
    "xdnn.closeHandle()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print inference data and plot\n",
    "Inference_Data = pd.DataFrame(Inference_Data)\n",
    "Inference_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.path as mpath\n",
    "f, ax = plt.subplots(figsize=(15, 10))\n",
    "plt.title('Number of connections to port')\n",
    "ax.set_xlabel(\"Batch Size\")\n",
    "plt.ylabel('Images Processed per second')\n",
    "plt.xticks(Inference_Data['batchSize'], Inference_Data['batchSize'])\n",
    "#plot images processed without initializing host memory ports- done on changing batch size\n",
    "ax.plot(Inference_Data['batchSize'],Inference_Data['imgsPerSecAc'],marker='x', markersize=10)\n",
    "#plot images processed with initializing host memory ports\n",
    "ax.plot(Inference_Data['batchSize'],Inference_Data['imgsPerSec'],marker='x', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
